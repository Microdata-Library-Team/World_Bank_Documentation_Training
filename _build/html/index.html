
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Quick Reference Guide for Data Archivists &#8212; Guide for Data Archivists  documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/theme_overrides.css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="#">Guide for Data Archivists  documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <img alt="_images/image1.png" src="_images/image1.png" />
<p><strong>International Household Survey Network</strong></p>
<p><strong>IHSN</strong></p>
<div class="section" id="quick-reference-guide-for-data-archivists">
<h1>Quick Reference Guide for Data Archivists<a class="headerlink" href="#quick-reference-guide-for-data-archivists" title="Permalink to this headline">¶</a></h1>
<p><strong>Version 2019 -04</strong></p>
<p><strong>Authors of this guide:</strong> Olivier Dupriez, Diana Marcela Sanchez Castro, Matthew Welch (The World Bank)</p>
<p>The production of this guide was made possible through a grant from the TFSCBDFID funding to the World Bank P167116/TF0A7461.</p>
<p><strong>Acknowledgments:</strong> Francois Fonteneau (PARIS21), Geoffrey Greenwell (PARIS21) Chris Rockmore (World Bank) and Jan Smit (ESCAP) provided valuable input to an earlier version of the document.
Trevor Croft (UNICEF) provided many of the examples of good practices for completing survey metadata.</p>
</div>
<div class="section" id="content">
<h1>Content<a class="headerlink" href="#content" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="#introduction">Introduction 1</a></p>
<p><a class="reference external" href="#gathering-and-preparing-the-data-set">1. Gathering and preparing the data set
2</a></p>
<p><a class="reference external" href="#gathering-and-preparing-the-documentation">2. Gathering and preparing the documentation
5</a></p>
<p><a class="reference external" href="#importing-data-and-establishing-relationships">3. Importing data and establishing relationships
5</a></p>
<p><a class="reference external" href="#importing-external-resources">4. Importing external resources 8</a></p>
<p><a class="reference external" href="#completing-metadata">5. Completing metadata 9</a></p>
<p><a class="reference external" href="#good-practices-for-completing-the-document-description">5.1. Good practices for completing the Document Description
10</a></p>
<p><a class="reference external" href="#good-practices-for-completing-the-study-description">5.2. Good practices for completing the Study Description
11</a></p>
<p><a class="reference external" href="#good-practices-for-completing-the-file-description">5.3. Good practices for completing the File Description
23</a></p>
<p><a class="reference external" href="#good-practices-for-completing-the-variables-description">5.4. Good practices for completing the Variables Description
24</a></p>
<p><a class="reference external" href="#good-practices-for-completing-the-external-resources-description">5.5. Good practices for completing the External Resources description
28</a></p>
<p><a class="reference external" href="#creating-variable-groups">6. Creating variable groups 29</a></p>
<p><a class="reference external" href="#running-validations-and-diagnostics">7. Running validations and diagnostics
30</a></p>
<p><a class="reference external" href="#generating-the-survey-documentation-in-pdf">8. Generating the survey documentation in PDF
31</a></p>
<p><a class="reference external" href="#independent-quality-review">9. Independent quality review 32</a></p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This <em>Quick Reference Guide for Data Archivists</em> provides data
archivists with guidelines to document a micro-dataset in compliance
with the Data Documentation Initiative (DDI) and the Dublin Core (DCMI)
metadata standards, using the World Bank Metadata Editor.</p>
<p>The World Bank Metadata Editor is an application designed to help document
data collection operations undertaken for different kinds of research
projects. The application is developed as an open-source tool by the World
Bank. A number of Metadata standards recognized as global models for
defining and describing different types of data have been integrated into
the Metadata Editor, these are: The Data Documentation Initiative
(DDI Codebook), The Dublin Core Metadata Initiative (DCMI) and the ISO
19139 for geospatial data.</p>
<p>The Metadata Editor is modelled on the Nesstar Publisher. As such it should
provide a familiar environment for the Nesstar users. As an added benefit,
the Metadata Editor is flexible and can support the documentation of
multiple-data types. Out of the box it supports the documentation of survey
data, time Series data, geospatial data, statistical tables, images,
analytical scripts and standalone publications or documents.</p>
<p>This Guide summarizes the process in 10 chronological steps:</p>
<ol class="arabic simple">
<li><p>Gathering and preparing the data set</p></li>
<li><p>Gathering and preparing the documentation</p></li>
<li><p>Importing data and establishing relationships</p></li>
<li><p>Importing external resources</p></li>
<li><p>Adding metadata</p></li>
<li><p>Creating variable groups (optional)</p></li>
<li><p>Running diagnostics</p></li>
<li><p>Generating the standard survey documentation using the PDF generator</p></li>
<li><p>Quality assessment</p></li>
<li><p>Producing the output for publication</p></li>
</ol>
<p>Also provided (in appendix) is the <em>IHSN DDI Reviewers’ Feedback Form</em>
which provides a standard tool for the assessment of survey metadata by
an external reviewer.</p>
<p>This Guide is not a Metadata Editor reference or training manual. It is
assumed that users are already familiar with the Editor. A <em>Metadata</em>
<em>Editor User’s Guide</em> is available at
<a class="reference external" href="https://metadata-editor.readthedocs.io/en/latest/">https://metadata-editor.readthedocs.io/en/latest/</a>.</p>
</div>
<div class="section" id="before-you-start-organizing-your-files">
<h2>Before you start: organizing your files<a class="headerlink" href="#before-you-start-organizing-your-files" title="Permalink to this headline">¶</a></h2>
<p>Documentation of a dataset will be most efficient if you
organize your data and other files properly. We recommend that, before
anything else, you create the necessary directories as follows:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 18%" />
<col style="width: 21%" />
<col style="width: 62%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="2" rowspan="3"><img alt="_images/Page2.png" src="_images/Page2.png" />
</td>
<td><ul>
<li><p>Create a directory for the survey.
We suggest you name it using the</p>
<p>country, survey’s year and the
abbreviated name, e.g. “UGA_2018_HIES”</p>
<p>for “Household Income and Expenditure
Survey” of Uganda collected in 2018.</p>
</li>
</ul>
</td>
</tr>
<tr class="row-even"><td><ul class="simple">
<li><p>Create various sub-directories for the.
data files (and for the various versions
of the dataset if relevant)</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><ul class="simple">
<li><p>Create sub-directories for the
documentation and for the program files
if relevant (see example).</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="gathering-and-preparing-the-data-set">
<h1>1. Gathering and preparing the data set<a class="headerlink" href="#gathering-and-preparing-the-data-set" title="Permalink to this headline">¶</a></h1>
<p>Gathering and preparing data is a process that requires great care.
Prior to documenting a dataset, it is important to ensure that you are
working with the most appropriate version of all the concerned data
files. If the dataset is meant for public release, one should work with
the final, edited, anonymous version of the dataset. If the dataset is
being documented for archiving and internal use only, one may include
the raw data as well as the final, fully edited files. The Metadata
Editor provides you with the possibility of documenting the specificity
of each version of the dataset.</p>
<p>Much of the quality of the output generated by the Editor will depend
upon the prior preparatory work. Although the Editor can make some
changes to the data, it is highly recommended that the necessary checks
and changes be made in advance using a statistical package and a script.
This ensures accurate and replicable results.</p>
<p>This section describes the various checks and balances involved in the
data preparation process, such as: making a diagnostic on the structure
of your data, cleaning it and identifying the various variables at the
outset. Listed below are some common data problems that users encounter:</p>
<ul class="simple">
<li><p>Absence of variables that uniquely identify each record of the dataset</p></li>
<li><p>Duplicate observations</p></li>
<li><p>Errors from merging multiple datasets</p></li>
<li><p>Encountering incomplete data when comparing the content of the data
files with the original survey questionnaire</p></li>
<li><p>Unlabelled data</p></li>
<li><p>Variables with missing values</p></li>
<li><p>Unnecessary or temporary variables in the data files</p></li>
<li><p>Data with sensitive information or direct identifiers</p></li>
</ul>
<p>Some practical examples using a statistical package are provided in
<em>Section A “Data Validations in Stata: Practical Examples</em>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><em>Note</em></p>
<p>If you are working in a data archive, be careful not to overwrite
your original variables. Since managing databases involves several
data-checking procedures, archive a new version in addition to the
original. Work on this new version, leaving the original data files
untouched.</p>
</td>
</tr>
</tbody>
</table>
<p>The following procedures are recommended for preparing your dataset(s):</p>
<div class="section" id="data-files-should-be-organized-in-a-hierarchical-format">
<h2>1.2. Data files should be organized in a hierarchical format<a class="headerlink" href="#data-files-should-be-organized-in-a-hierarchical-format" title="Permalink to this headline">¶</a></h2>
<p>Look at your data and visualize it to understand its structure.
It is preferable to organize your files in a hierarchical format
instead of a flat format. In a hierarchical format, columns
contain specific information about all possible units of analysis
and rows form the individual observations (households,
establishments, products, communities/countries, or any
combination of those). Hierarchical files are easier to analyse,
as they contain fewer columns that store the same information and
are more compact. A flat format contains multiple columns with
information on only one specific unit of analysis, so the
information becomes redundant. For example, the information
provided in one column is about the household head, and the row
provides information on the child in the household.</p>
<p><strong>Table 1. Flat Format</strong></p>
<img alt="_images/Page4_1.png" src="_images/Page4_1.png" />
<p><strong>Table 2. Hierarchical Format</strong></p>
<img alt="_images/Page4_2.png" src="_images/Page4_2.png" />
<p><em>Tables 1 and 2</em> illustrate the two data structures. They
contain the same information about six people on age and their
relationship with the head of the household. The flat dataset
(Table 1) stores the information on each family member in a new
column. Note that for every additional member or characteristic,
the dataset gets flatter and wider. The hierarchical dataset
(see Table 2) has one observation and one row per person.
Each variable contains a value that measures the same attribute
across people and each record contains all values measured on the
same person across variables. For every additional member
characteristic, the dataset maintains the same number of columns,
gains additional rows and gets longer and less flat compared to
<em>Table 1</em>. The first two columns of this dataset have a
hierarchical structure, where the ID member column is nested
inside the ID household column.</p>
<p>Hierarchical files are easier to manage. Suppose in this example
that there were many characteristics measured for everyone, the
hierarchical structure would be a more convenient format because
for each new characteristic, the dataset creates only one
additional column, whereas, in the flat structure, it would
create as many columns as there are people in the data with such
characteristics.</p>
</div>
<div class="section" id="datasets-with-multiple-units-of-analysis-should-be-stored-in-different-data-files">
<h2>1.2. Datasets with multiple units of analysis should be stored in different data files<a class="headerlink" href="#datasets-with-multiple-units-of-analysis-should-be-stored-in-different-data-files" title="Permalink to this headline">¶</a></h2>
<p>It is recommended that you store your data in different files
when you have multiple observational units. For example, <em>Table 3</em>
shows a dataset that has both household-level data (columns on
the type of dwelling and walls material) and individual-level
data (columns on the marital status, work status, and worker
category). Note that storing both levels of information in one
dataset will result in a repetition of household characteristics
for each household member. In Table 3, the information about the
columns ‘type of dwelling’ and ‘wall material’ is repeated for
everyone. Sometimes, this duplication is inefficient, and it is
easier to have the dataset broken down by observational unit, into
multiple files. In this example, it would be simpler to create two
files:  one for the household characteristics and another for the
individual characteristics. The two files can be connected through
a unique identifier, which in this case will be the household ID and
member ID. We discuss the need for this unique identifier further on
in this text as well.</p>
<p><strong>Table 3. Single data set with more than one observational unit</strong></p>
<img alt="_images/Page5.png" src="_images/Page5.png" />
</div>
<div class="section" id="columns-in-a-dataset-should-represent-variables-not-values">
<h2>1.3. Columns in a dataset should represent variables, not values<a class="headerlink" href="#columns-in-a-dataset-should-represent-variables-not-values" title="Permalink to this headline">¶</a></h2>
<p>It is recommended that columns represent variables (e.g., sex, age,
marital status) and rows represent observations (e.g., individuals,
households, firms, products and so forth). In some datasets, columns
instead of describing variables or attributes, describe values, which
means that one variable is broken into segments and each one is
stored in different columns. While this dataset structure can be
useful for some analysis, the standard data structure where columns
are variables and not values is the norm.</p>
<p>For example, <em>Table 4</em> (options 1 and 2) gives information at the
individual-level on marital status, relationship with the head of
the household and age. The difference between both tables is how the
variable ‘age’ is reported. Option 1 had broken the variable ‘age’
into segments. This practice makes your data: i) messier, it has
values of the variable as headings, and ii) inefficient, it increases
the size of the dataset. Option 2 is recommended since there is only
one heading and store of the information occupies less space, allowing
the user to identify the structure of the data in a clear manner.</p>
<p><strong>Table 4. Data Structures: Hypothetical datasets</strong></p>
<img alt="_images/Page6_1.png" src="_images/Page6_1.png" />
</div>
<div class="section" id="each-observation-in-every-file-must-have-a-unique-identifier">
<h2>1.4. Each observation in every file must have a unique identifier<a class="headerlink" href="#each-observation-in-every-file-must-have-a-unique-identifier" title="Permalink to this headline">¶</a></h2>
<p>Before you check for uniqueness of the identifiers in your files, you
need to figure out the unit of analysis. Even if you are not the data
producer, it is often easy to identify it. You can always review the
documentation to see if the information has been provided. Below, some
examples of units of analysis:</p>
<p><strong>Table 5. Unit of Analysis by Study type</strong></p>
<img alt="_images/Page6_2.png" src="_images/Page6_2.png" />
<p>Once you recognize the unit of analysis, the next step is to identify
the column that uniquely identifies each record. If a dataset contains
multiple related files, each record in every file must have a unique
identifier. The data producer can also choose multiple variables to
define a unique identifier. In that case, more than one column in a
dataset is used to guarantee uniqueness. These identifiers are also
called <strong>key variables</strong> or <strong>ID variables</strong>. The variable(s) should
not contain missing values or have any duplicates. They are used by
statistical packages such as SPSS, R or Stata when data files need
to be merged for analysis</p>
<p>The absence of a unique identifier is a data quality issue, so one
needs to ensure that the unique IDs remain fixed/present during the
data cleaning process. If this correction is not possible, the archivist
should note the anomalies in the documentation process.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><em>Best Practices</em></p>
<ul class="simple">
<li><p>It is recommended that ID variables be defined as a numeric since
sorting and filtering records is much more efficient when
variables are numeric.</p></li>
<li><p>ID variables should not contain spaces, special characters or
accents, since they may suffer modifications when the dataset is
converted in different formats.</p></li>
<li><p>For the convenience of users of the data, avoid identifiers
consisting of too many variables. For example, in a household
survey, the household identifier should ideally be a single
variable (which you may create by concatenating a group of
variables <a class="footnote-reference brackets" href="#id4" id="id1">3</a>), and the individual identifier should be the
combination of only two variables (the household ID, and the
sequential number of each member).</p></li>
<li><p>It is recommended that you generate an ID based on a sequential
number, however, keep in mind that it should not be too long
because statistical packages and spreadsheet programs store a
number of digits of precision, so opening a data set that contains
ID variables with many characters, might result in truncated
fields. For instance, the limit of the number of characters in
Microsoft Excel is 15, so it changes any digits past the fifteenth
place to zeroes.</p></li>
<li><p>If you prepare your data files for public dissemination, it may be
preferable to generate a unique household identification that
would <strong>not</strong> be a compilation of geographic codes (because
geographic codes are highly identifying). This recommendation is
to ensure anonymity and will be explained in further detail later
on in this text. The following example shows how to construct a
unique identifier without using detailed information provided by
the geographic codes.</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="simple">
<dt>Example</dt><dd><ul class="simple">
<li><p>Suppose the unique identification of a household is a combination of
of variables PROV (Province), DIST (District), EA (Enumeration Area),
HHNUM (Household Number). Options 2 and 3 are recommended. Note that
if option 3 is chosen, it is crucial o preserve (but not distribute)
a file that would provide the mapping between the original codes and
the new HHID.</p></li>
</ul>
</dd>
</dl>
<table class="docutils align-default">
<colgroup>
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 15%" />
<col style="width: 30%" />
<col style="width: 32%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head" colspan="4"><dl class="simple">
<dt>Option 1: Use a combination of</dt><dd><p>four variables</p>
</dd>
</dl>
</th>
<th class="head"><dl class="simple">
<dt>Option 2: Generate a</dt><dd><p>concatenated ID</p>
</dd>
</dl>
</th>
<th class="head"><dl class="simple">
<dt>Option 3: Generate a</dt><dd><p>sequential number</p>
</dd>
</dl>
</th>
</tr>
<tr class="row-even"><th class="head"><p>PROV</p></th>
<th class="head"><p>DIST</p></th>
<th class="head"><p>EA</p></th>
<th class="head"><p>HHNUM</p></th>
<th class="head"><p>HHID</p></th>
<th class="head"><p>HHID</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd"><td><p>12</p></td>
<td><p>01</p></td>
<td><p>014</p></td>
<td><p>004</p></td>
<td><p>1201014004</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>12</p></td>
<td><p>01</p></td>
<td><p>015</p></td>
<td><p>001</p></td>
<td><p>1201015001</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><p>07</p></td>
<td><p>008</p></td>
<td><p>112</p></td>
<td><p>1307008112</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even"><td><p>Etc</p></td>
<td><p>Etc</p></td>
<td><p>Etc</p></td>
<td><p>Etc</p></td>
<td><p>Etc</p></td>
<td><p>Etc</p></td>
</tr>
</tbody>
</table>
<p>Once you recognize the unit of analysis and the variable that uniquely
identifies it, the following checks are suggested:</p>
<ul class="simple">
<li><p>Even if the data set has a variable with a label “unique identifier”,
it is important to confirm that this variable truly does uniquely
identify each record. To confirm or even to find out what the unique
identifier is, you can make use of the <em>-duplicate-</em> function in SPSS or
the <em>-isid-</em> command in Stata (for R, do as shown in <em>Table 6</em>). For more
details, refer to <em>Example 1 and Example 2 of Section A</em>.</p></li>
</ul>
<p><strong>Table 6. Check for unique identifiers: STATA/R/SPSS Commands</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 39%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>STATA Code</strong></p></td>
<td><p><strong>R Code</strong></p></td>
<td><p><strong>SPSS Function</strong></p></td>
</tr>
<tr class="row-even"><td><p><em>use “household.dta”</em></p>
<p><em>isid “key1” “key2”</em></p>
</td>
<td><p><em>my_data&lt;-</em>
<em>read_dta(“household.dta”)</em></p>
<p><em>id &lt;-c( “key1” , ” key2”)</em></p>
<p><em>isid(my_data, id,</em>
<em>verbose = FALSE)</em></p>
</td>
<td><p><em>GET</em>
<em>FILE=’household.sav’</em></p>
<p><em>execute.</em></p>
<p>From the menu choose:</p>
<ul class="simple">
<li><p>Data&gt;Indentify
Duplicate Cases</p></li>
<li><p>Select Key Variables</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>Finally, check that the ID variable for the unit of observation doesn’t
have missing or assigned zero/null values. Ensure that the datasets are
sorted and arranged by their unique identifiers.</p></li>
</ul>
<p><em>Table 7</em> below gives a hypothetical example. In this dataset, the
highlighted columns (hh1, hh2, hh3) are the key variables, which means that
they are supposed to make up the unique identifier. However, looking at
those variables, we can identify some problems: the key variables do not
uniquely identify each observation as they have the same values in rows 4
and 5, they also have some missing values (represented by asterisks),
assigned zero values and some null values (those that say NA, don’t know).
All these issues suggest that those variables are not the key variables,
and one needs to go back and double-check the data documentation.
Alternatively, the archivist could check with the data producer and ask
them how to fix these variables, in case those are indeed the key variables.</p>
<p><strong>Table 7. Check for unique identifiers: Hypothetical data set</strong></p>
<img alt="_images/Page8_2.png" src="_images/Page8_2.png" />
<p><em>Example 3</em> provides further details and describes the steps involved in
performing a validation when the identifier is made of multiple variables
(see <em>Section A</em>).</p>
</div>
<div class="section" id="identifying-duplicate-observations">
<h2>1.5. Identifying duplicate observations<a class="headerlink" href="#identifying-duplicate-observations" title="Permalink to this headline">¶</a></h2>
<p>One way to rule out problems with the unique identifier is to check if
there are duplicate observations (records with identical values for all
variables, not just the unique identifiers). Duplicate observations can
generate erroneous analysis and cause data management problems. Some
possible reasons for duplicate data are, for example, the same record
being entered twice during data collection. They could also arise from
an incorrect reading of the questionnaires during the scanning process
if paper-based methods are being used.</p>
<p>Identifying duplicate observations is a crucial step. Correcting this
issue may involve eliminating the duplicates from the dataset or giving
them some other appropriate treatment.</p>
<p>Statistical packages have several commands that help identify duplicates.
<em>Table 8</em> shows examples of these commands in STATA, R and SPSS. The STATA
command <em>-duplicates report-</em> generates a table that summarizes the number
of copies for each record (across all variables). The command
<em>-duplicates tag-</em> allows us to distinguish between duplicates and unique
observations. For more details, refer to <em>Example 4</em> of <em>Section A</em>.</p>
<p><strong>Table 8. Check for duplicates observations: STATA/R/SPSS Commands</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 39%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>STATA Code</strong></p></td>
<td><p><strong>R Code</strong></p></td>
<td><p><strong>SPSS Function</strong></p></td>
</tr>
<tr class="row-even"><td><p><em>use “household.dta”</em></p>
<p><em>duplicates report</em></p>
<p><em>duplicates tag,</em>
<em>generate(newvar)</em></p>
</td>
<td><p><em>my_data&lt;-</em>
<em>load(“household.rda”)</em></p>
<p><em>household</em>
<em>[duplicated(household),]</em></p>
</td>
<td><p><em>GET</em>
<em>FILE=’household.sav’</em></p>
<p><em>execute.</em></p>
<p>From the menu choose:</p>
<ul class="simple">
<li><p>Data&gt;Indentify
Duplicate Cases</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="ensure-that-each-individual-dataset-can-be-combined-into-a-single-database">
<h2>1.6. Ensure that each individual dataset can be combined into a single database<a class="headerlink" href="#ensure-that-each-individual-dataset-can-be-combined-into-a-single-database" title="Permalink to this headline">¶</a></h2>
<p>For organizational purposes, surveys are often stored in different datasets.
Therefore, checking the relationship between the data files is an essential
step to keep in mind throughout the data validation process. The role of
the data producer is to store the information as efficiently as possible,
which implies storing data in different files. The role of the data user is
to analyse the data as holistically as possible, which could sometimes mean
that they might have to join all the different data files into a single
file to facilitate analysis. It is essential to ensure that each of the
separate files can be combined (merged or appended depending on the case)
into a single file, should the data user want to undertake this step.</p>
<p>Use statistical software to validate that all files can be combined into
one. For a household survey, for example, verify that all records in the
individual-level files have a corresponding household in the household-level
master file. Also, verify that all households have at least on
e corresponding record in the household-roster file that lists all
individuals. Below, some considerations to keep in mind before merging data
files:</p>
<ul class="simple">
<li><p>The variable name of the identifier should be the same across all datasets.</p></li>
<li><p>The ID variables need to be the same type (either both numeric or both
string) across all databases.</p></li>
<li><p>Except for ID variables, it is highly recommended that the databases don’t
share the same variable names or labels.</p></li>
</ul>
<dl>
<dt>Example</dt><dd><ul class="simple">
<li><p>A household survey is disseminated in two datasets; one contains
information about household characteristics and the other contains
information on the children (administered only to mothers or caretakers).
To build a dataset containing all the information about the household
characteristics, including where the children live, one needs to combine
these files. Users are thus assured that all observations in the
child-level file have corresponding household information.</p></li>
</ul>
<p><strong>Joining data files: Hypothetical data set</strong></p>
</dd>
</dl>
<img alt="_images/Page10_1.png" src="_images/Page10_1.png" />
<img alt="_images/Page10_2.png" src="_images/Page10_2.png" />
<p>Statistical packages have some commands that allows us to combine datasets
using one or multiple unique identifiers. <em>Table 9</em> shows examples of
these commands/functions in STATA, R and SPSS. For more details, refer to
<em>Example 5</em> of <em>Section A</em>.</p>
<p><strong>Table 9. Joining data files: STATA/R/SPSS Commands</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 39%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>STATA Code</strong></p></td>
<td><p><strong>R Code</strong></p></td>
<td><p><strong>SPSS Function</strong></p></td>
</tr>
<tr class="row-even"><td><p><em>use “household.dta”</em></p>
<p><em>merge 1:m hh1 hh2</em>
<em>hh3 using</em>
<em>“individuals.dta”</em></p>
</td>
<td><p><em>household&lt;-</em>
<em>load(“household.rda”)</em></p>
<p><em>individuals&lt;-</em>
<em>load(“individuals.rda”)</em></p>
<p><em>md&lt;-merge(household,</em>
<em>individuals, by=c(“hh1”,
“hh2”, “hh3”),all=TRUE)</em></p>
</td>
<td><p><em>GET</em>
<em>FILE=’household.sav’</em></p>
<p><em>execute.</em></p>
<p>From the menu choose:</p>
<ul class="simple">
<li><p>Data&gt;Merge Files&gt;
Add Variables</p></li>
<li><p>Select the data file
to merge</p></li>
<li><p>Select Key Variables</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Panel datasets should be stored in different files as well. Having one
file per data collection period is a good practice. To combine the different
periods of a panel dataset, the data user could merge them (Adding variables
to the existing observations for the same period) or append them (Adding
observations for a different period to the existing variables). To make sure
that panels can be properly appended, the following checks are suggested:</p>
<ul class="simple">
<li><p>Check for the column(s) that identifies the period of the data (Year, Wave,
Serie, etc.).</p></li>
<li><p>The variable names and variable types should be the same across all datasets.</p></li>
<li><p>Ensure that the variables use the same label and the same coding across all
datasets.</p></li>
</ul>
<p>In SPSS, use the function <em>“Append new records”</em> and in STATA the command
<em>-append-</em> to combine datasets vertically.</p>
</div>
<div class="section" id="check-for-variables-with-missing-values">
<h2>1.7. Check for variables with missing values<a class="headerlink" href="#check-for-variables-with-missing-values" title="Permalink to this headline">¶</a></h2>
<p>Getting data ready for documentation also involves checking for variables
that do not provide complete information because they are full of missing
values. This step is important because missing values can have unexpected
effects on the data analysis process. Typically, missing values are defined
as a character (.a, .b, single period or asterisks), special numeric
(-1, -2) or blanks. Variables entirely comprised of missing values should
ideally not be included in the dataset. However, before excluding them, it
is useful to check whether the missing values are expected according to the
questionnaire, and the skip patterns.</p>
<p>For example, a hypothetical household survey at the individual-level
(Table 10) provides information about the respondent’s employment status.
The survey identifies if the respondent is employed in Column D, and then
provides information about the worker category in Column E, but only for
those who reported being employed in Column D. This means that those who
answered ‘unemployed’ in column D should have a valid missing value in
column E. In other words, this is a pattern in the missing values that
should be observed and duly noted.</p>
<p>On the other hand, Columns F and G are used to determine if the people who
are not employed are looking for a job and are actively seeking it. These
questions are not asked to the employed people (those who answered “yes”
in Column D), which mean that again, the missing values in those columns
correspond with what is expected. However, Column H contains information
for all employed individuals, so missing values in this column suggest
that there is a problem in the data and should be addressed. Therefore,
one should not blindly delete missing values at the outset without checking
for these patterns.</p>
<p><strong>Table 10. Checking for Missing Values: Hypothetical data set</strong></p>
<img alt="_images/Page12.png" src="_images/Page12.png" />
<p>In SPSS, use the function <em>“Missing Value Analysis”</em> and in R, do as shown
in <em>Table 11</em>. You can also use the STATA command <em>-misstable summarize-</em>
that produces a report that counts all the missing values. You can also use
the <em>-rowmiss()-</em> command with <em>-egen-</em> to generate the number of missing
values among the specified variables. For more details, refer to
<em>Example 6</em> of <em>Section A</em>.</p>
<p><strong>Table 11. Counting Missing Values: STATA/R/SPSS Commands</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 39%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>STATA Code</strong></p></td>
<td><p><strong>R Code</strong></p></td>
<td><p><strong>SPSS Function</strong></p></td>
</tr>
<tr class="row-even"><td><p><em>use “individual.dta”</em></p>
<p><em>misstable summarize</em></p>
</td>
<td><p><em>individual&lt;-</em>
<em>load(“individual.rda”)</em></p>
<p><em>colSums</em>
<em>(is.na(individual))</em></p>
<p><em>colMeans</em>
<em>(is.na(individual))</em></p>
</td>
<td><p><em>GET</em>
<em>FILE=</em>
<em>‘individual.sav’</em></p>
<p><em>execute.</em></p>
<p>From the menu choose:</p>
<ul class="simple">
<li><p>Data&gt;Analyze&gt;
Missing Value
Analysis</p></li>
<li><p>Select “Use All
Variables”</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><em>Best Practices</em></p>
<p>Since there are different reasons for missing values, data producer
should code them with negative integers or letters to distinguish
the missing values and valid data. For instance, (− 1) might be the
code for “Don’t Know”, (-2) the code for “Refused to Answer” and
(-9) code for “Not Applicable”.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="check-improper-value-ranges">
<h2>1.8. Check Improper value ranges<a class="headerlink" href="#check-improper-value-ranges" title="Permalink to this headline">¶</a></h2>
<p>It is helpful to generate descriptive statistics for all variables
(frequencies for discrete variables; min/max/mean for continuous
variables) and verify that these statistics look reasonable. Just as
there are variables that must take on only specific values, such as “F”
and “M” for gender, there are also some variables that can take on
several values (such as age or height). However, those values must fit
a particular range. For example, we don’t expect negative values, or
typically see values over 115 years for age.</p>
<p>Values for categorical variables should be guided by the questionnaire
(or separate documentation for constructed variables). If we have an
education variable that has 9 response options in the questionnaire,
the corresponding ‘education’ variable in the dataset should have 9
categories. We should not observe more than 9 unique values for this
variable. Similarly, for any questions in the survey for which the
options are only “yes”, “no” and “other”, we should not observe more
than these 3 unique values.  When out of range values exist, this might
signal data cleaning issues.</p>
<p><em>Table 12</em> shows examples of some commands/functions in STATA, R and
SPSS.</p>
<p><strong>Table 12. Generate descriptive statistics: STATA/R/SPSS Commands</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 39%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>STATA Code</strong></p></td>
<td><p><strong>R Code</strong></p></td>
<td><p><strong>SPSS Function</strong></p></td>
</tr>
<tr class="row-even"><td><p><em>use “individual.dta”</em></p>
<p><em>summarize</em></p>
</td>
<td><p><em>individual&lt;-</em>
<em>load(“individual.rda”)</em></p>
<p><em>summary(individual)</em></p>
</td>
<td><p><em>GET</em>
<em>FILE=</em>
<em>‘individual.sav’</em></p>
<p><em>execute.</em></p>
<p>From the menu choose:</p>
<ul class="simple">
<li><p>Data&gt;Analyze&gt;
Descriptive
Statistics&gt;
Frequencies</p></li>
<li><p>Select “Statistics”</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="verify-that-the-number-of-records-in-each-file-corresponds-to-what-is-expected">
<h2>1.9. Verify that the number of records in each file corresponds to what is expected<a class="headerlink" href="#verify-that-the-number-of-records-in-each-file-corresponds-to-what-is-expected" title="Permalink to this headline">¶</a></h2>
<p>The technical documentation helps to form some expectations about the size
of the dataset. Make sure that in all the files, the number of records is
the same as (or is similar to) what is explicitly stated in the sample
design of your survey.</p>
<p>Suppose that you have a household survey and according to the documentation
the sample size is 50,321 households. Consequently, the file that contains
the household-level information should have a similar number of observations.
When this is not the case, you should be able to account for this difference
in data documentation.</p>
<p>On the other hand, even if the number of individual records is not available
in the documentation, you can still perform a rough check on the files. For
example, if you have the household level file and the person level file, the
latter should be between 2 or 6 times larger than the former, depending on
the average household size in the country for which the information has been
collected. Another example is to compare the household level file of an
expenditure survey with the consumption level file (at the product-level).</p>
<p>The latter should have n times the number of observations than the former,
where n is the average number of products that each household records in the
survey.</p>
</div>
<div class="section" id="datasets-must-contain-all-variables-from-the-questionnaire-and-be-in-a-logic-sequence">
<h2>1.10. Datasets must contain all variables from the questionnaire and be in a logic sequence<a class="headerlink" href="#datasets-must-contain-all-variables-from-the-questionnaire-and-be-in-a-logic-sequence" title="Permalink to this headline">¶</a></h2>
<p>Verify the completeness of your data files by comparing the content of these
files with the survey questionnaire. All variables in the questionnaire should
appear in the dataset, except those excluded on purpose by the producer of the
data because of reasons of confidentiality (see numeral <em>1.15</em>).
Cross-checking with the questionnaire(s) is needed to ensure that all sections
are included in the dataset.</p>
<p>Additionally, it is a good practice to make sure that the database is sorted
in the same order as the questionnaire. This practice will help users navigate
seamlessly across the dataset using the questionnaire as a route map.</p>
<p>The Stata command <em>-describe-</em> displays the names, variable labels and other
characteristics, which helps us verify that no variables have been omitted in
the database. It simultaneously confirms that all variables are correctly
ordered. Refer to <em>Example 7</em> of <em>Section A</em> for further details.</p>
</div>
<div class="section" id="include-the-relevant-weighting-coefficients-and-variables-identifying-the-stratification-levels">
<h2>1.11. Include the relevant weighting coefficients and variables identifying the stratification levels<a class="headerlink" href="#include-the-relevant-weighting-coefficients-and-variables-identifying-the-stratification-levels" title="Permalink to this headline">¶</a></h2>
<p>All data files of a sample survey should have clearly labelled variable(s)
with information on the survey weights. Sample surveys need to be
representative of a broader population for which the data is collected,
and the user needs the survey weights for almost every analysis performed.
In the case of household surveys, the survey weights are equal among
members of the same household but differ across households. Weights are
positive and strictly higher than zero. They should not have a larger
value than the population for which the survey is representative.</p>
<p>A more detailed description of how the survey weights would look like
should be provided in the documentation of the survey.  Based on it, you
can perform some basic range checks. Notice that Census datasets do not
need weights since a census collects data on all the individuals in the
population. There are however some exceptions, for example in the case of
IPUMS, the data collected are not full censuses but census samples, so
weights are required in this context.</p>
<p>Additionally, for sample surveys, verify that the variables identifying
the various levels of stratification and the primary sampling unit are
included and easily identifiable in at least one of the data files. These
variables are needed for the calculation of sampling errors.</p>
</div>
<div class="section" id="variables-and-codes-for-categorical-variables-must-be-labelled">
<h2>1.12. Variables and codes for categorical variables must be labelled<a class="headerlink" href="#variables-and-codes-for-categorical-variables-must-be-labelled" title="Permalink to this headline">¶</a></h2>
<p><strong>Variable labels</strong></p>
<p>Labels should be short and precise. They should provide a clear
indication of what information is contained in the variables. Variable
labels are brief descriptions or attributes of each variable. Without
variable labels, users are not able to link the variables in the
database to the questions of the questionnaire. So, one should ensure
that all variables are labelled.</p>
<p>Additionally, even if variables are fully labelled, the following
practices must be considered:</p>
<ul class="simple">
<li><p>Variable labels can be up to 80 characters long in Stata and 255 in
SPSS, however, it is recommended that labels be informative,  short
and accurate.</p></li>
<li><p>It is a common practice to have a literal question from the survey as
a variable label. However, the literal questions are usually longer
than the maximum number of characters, so this is not an advisable
practice.</p></li>
<li><p>The same label should not be used for two different variables.</p></li>
</ul>
<p><strong>Value labels</strong></p>
<p>Label values are used for categorical variables. To ensure the correct
encoding of data, it is important to check that the stored values in
those variables correspond to what is expected according to the
questionnaire. In the case of continuous variables, we also suggest the
checking of ranges. For instance, if the question is about the number of
working hours, the variable should not have negative values.</p>
<p>You can compare variable labels in the dataset to those in the
questionnaire using the <em>–codebook-</em> Stata command or <em>–labelbook</em>-.
Refer to <em>Example 8</em> of <em>Section A</em> for further details.</p>
</div>
<div class="section" id="temporary-calculated-or-derived-variables-should-not-be-disseminated">
<h2>1.13.  Temporary, calculated or derived variables should not be disseminated<a class="headerlink" href="#temporary-calculated-or-derived-variables-should-not-be-disseminated" title="Permalink to this headline">¶</a></h2>
<p>Remove all unnecessary or temporary variables from the data files. These
variables are not collected in the field and present no interest for users.</p>
<p>The data producer could generate variables that are only needed during the
quality control process but are not relevant to the final data user. For
example, the variable “_merge” in Stata is generated automatically after
performing the check described in the Numeral <em>1.6</em>, when the data producer
wants to see if the datasets match properly. Variables that group categories
of a question, dummy variables that identify a question’s category are all
variables produced during the coding process that are not relevant once the
analysis is completed.</p>
<p>There are cases in which calculated variables may be useful to the users, so
they must be documented in the metadata. For example, most Labor Force Surveys
(LFS) contain derived dummy variables to identify the sections of the
population that are employed or unemployed. These variables are generated
using multiple questions from the dataset and are essential elements of any
LFS. Most data users prefer to make use of them instead of computing them on
their own, to reduce the risk of error. This is a strong argument to make a
case for keeping these variables in the dataset, despite them being a
by-product of other original variables.</p>
<p>To be useful, those variables that remain in the dataset must be well
documented, else they, they may be useless to or misunderstood by users.</p>
</div>
<div class="section" id="check-that-the-data-types-are-correct">
<h2>1.14. Check that the data types are correct<a class="headerlink" href="#check-that-the-data-types-are-correct" title="Permalink to this headline">¶</a></h2>
<p>Do not include string variables if they can be converted into numeric
variables. Look at your data and check the variables’ types, particularly
for those that you expect to be numeric (age, years, number of
persons/employees/hours, income, purchases/expenditures, weights, and so
forth). If there are numeric variables stored as string variables, your
data needs cleaning.</p>
<p>For example, <em>Table 13</em> contains a data set at the individual-level with
some variables that should be numeric. The columns B (Age) and E
(Working Weeks) are stored as numeric variables, which is fine. However,
the variables ‘Number of working of hours per week’ (Column G), ‘Number
of persons working at the business’ (Column H) and ‘Monthly Income’
(Column I) are loaded as strings because there are non-numeric values
(don’t know, skip, refused to answer) and some missing values present.
Those variables need to be cleaned and converted from string variables
to numeric variables.</p>
<p><strong>Table 13. Checking Data Types: Hypothetical data set</strong></p>
<img alt="_images/Page16.png" src="_images/Page16.png" />
<p>Statistical packages have some commands that allows us to make such
conversions. <em>Table 14</em> shows examples of these commands/functions in
STATA, R and SPSS.</p>
<p><strong>Table 14. Convert string variables to numeric: STATA/R/SPSS Commands</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 39%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>STATA Code</strong></p></td>
<td><p><strong>R Code</strong></p></td>
<td><p><strong>SPSS Function</strong></p></td>
</tr>
<tr class="row-even"><td><p><em>use “individual.dta”</em></p>
<p><em>destring (varname),</em>
<em>{generate|replace}</em></p>
</td>
<td><p><em>individual&lt;-</em>
<em>load(“individual.rda”)</em></p>
<p><em>Individual $varname =</em>
<em>as.numeric(Individual</em>
<em>$varname)</em></p>
</td>
<td><p><em>GET</em>
<em>FILE=</em>
<em>‘individual.sav’</em></p>
<p><em>execute.</em></p>
<p>From the menu choose:</p>
<ul class="simple">
<li><p>Data&gt;Transform&gt;
Recode into Same|
Different Variables</p></li>
<li><p>Select the variable</p></li>
<li><p>Select “Old and New
Values” and Recode
it</p></li>
<li><p>Select “Convert
numeric strings to
numbers (‘5’-&gt;5)</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="datasets-must-not-have-directed-identifiers">
<h2>1.15. Datasets must not have directed identifiers<a class="headerlink" href="#datasets-must-not-have-directed-identifiers" title="Permalink to this headline">¶</a></h2>
<p>One must verify that in all data files, sensitive information or direct
identifiers that could reveal the identity of the respondent directly
(names, addresses, GPS coordinates, phone numbers, etc.) have been removed.
Check to ensure this information is not in the dataset(s). If it is, those
variables need to be removed from shared datasets.</p>
<p>Keep in mind that if you are preparing a dataset for public release, you
need a cleaned, anonymous dataset.  Removing all direct identifiers is the
first key step to ensuring the anonymity of the participants. However,
before you start any privacy procedures, you should always check your data.</p>
<p>For more information on how to apply statistical disclosure control (SDC)
methods to data before release, see the document “Introduction to
Statistical Disclosure Control (SDC)” available at
<a class="reference external" href="http://ihsn.org/sites/default/files/resources/ihsn-working-paper-007-Oct27.pdf">http://ihsn.org/sites/default/files/resources/ihsn-working-paper-007-Oct27.pdf</a></p>
</div>
<div class="section" id="compress-the-variables-to-reduce-the-file-size">
<h2>1.16. Compress the variables to reduce the file size<a class="headerlink" href="#compress-the-variables-to-reduce-the-file-size" title="Permalink to this headline">¶</a></h2>
<p>Compress the variables consist of reducing the size of the data file without
loss of precision or modifying the information that it provides. Listed
below are some reasons why compressing a data set may be a useful practice
for at least three reasons: First, it makes faster the process of creating
backups, uploading and downloading data files from your data repository or
any Survey Catalog. Second, it reduces the time that data users will need
to spend working with the data. Additionally, it will make the data more
accessible to the different type of users; sometimes the data size will
impose restrictions on those users who lack high computational power.
Third, it will help to free up disk space in the server where you store
your data</p>
<dl>
<dt>Example</dt><dd><ul class="simple">
<li><p><em>Table 15</em> shows two versions of one dataset that provides
individual-levelinformation about the year of the first union, age,
school attendance,and health insurance. There is no difference in
the appearance of both datasets. However, version 1 was saving
uncompressed and version 2compressed. In the uncompressed version,
the variables “ID” and “Year” are stored as double, which means that
they can store number with high decimal precision, but they
are designed to only record information of integer numbers between
-32,767 and 32,740. So, the compressed version changed the storage
type of these variables to int and saves 6 bytes per observation.
Similarly, other variables like “age” and “school attendance” are
stored as a byte in the compressed version, which saves 7 bytes
per observation when are compared to the uncompressed version.
Let’s suppose that one has a data set with 500 variables like these,
the total savings would be 3500 bytes per observation; if this data set
has 50.000 observations, it means that the savings in memory space
would be around 175 megabytes.</p></li>
</ul>
<p><strong>Table 15. Compressing the Variables: Hypothetical data set</strong></p>
</dd>
</dl>
<img alt="_images/Page18_1.png" src="_images/Page18_1.png" />
<img alt="_images/Page18_2.png" src="_images/Page18_2.png" />
<p>Use the <em>compress</em> command in Stata, or the <em>compress</em> option when you
save a SPSS data file.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><em>Suggestion:</em></p>
<p>If you are in the process of establishing a data archive and plan
to document a collection of surveys, undertake a full inventory of
all existing data and metadata before you start the documentation.
Use the IHSN Inventory Guidelines and Forms to before you start the
documentation. Use the <em>IHSN Inventory Guidelines and Forms</em> to
facilitate this inventory (available at www.surveynetwork.org).</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="gathering-and-preparing-the-documentation">
<h1>2. Gathering and preparing the documentation<a class="headerlink" href="#gathering-and-preparing-the-documentation" title="Permalink to this headline">¶</a></h1>
<p>All information related to the survey may be useful and should be
archived (even if not all will be disseminated to the public). This
includes not only technical documents such as the questionnaires or list
of codes (obviously needed by data users), but also administrative
reports (potentially useful for implementation of future surveys), and
other documents such as a compilation of the comments provided by
stakeholders at the time the questionnaire was designed, etc. Resources
to be included if available include:</p>
<ul class="simple">
<li><p>The survey questionnaire(s); make sure that the cover page and all
sections are included. If the questionnaire exists in multiple
languages, provide all versions.</p></li>
<li><p>All technical, analytical and administrative documents</p>
<ul>
<li><p>Sampling information</p></li>
<li><p>Interviewers and supervisor’s manuals</p></li>
<li><p>List of codes</p></li>
<li><p>Instructions for data editing</p></li>
<li><p>Survey report (tabulation and analysis)</p></li>
<li><p>Analytical papers and policy briefs that made use of the data</p></li>
<li><p>Survey budget and other key planning documents</p></li>
<li><p>PowerPoint presentations and other related material</p></li>
</ul>
</li>
<li><p>Computer programs (used for data entry, editing, tabulation and
analysis)</p></li>
<li><p>Photos</p></li>
<li><p>Tables</p></li>
<li><p>Maps</p></li>
<li><p>Survey promotional/informational materials (flyers, videos, posters,
songs, etc.)</p></li>
</ul>
<p>Documents available in electronic format (MS-Word, Excel, and others)
must be preserved in their original format and in PDF format.</p>
<p>All documents available only on hard copy must be scanned. Use low
resolution graphics, and black &amp; white option (unless it is crucial to
preserve colours) to avoid large file sizes. A scanning resolution of
300 dpi is recommended. Save the scanned documents in PDF format. OCR is
useful, although not required.</p>
<p>Scan all resources with an updated virus detection application.</p>
</div>
<div class="section" id="importing-data-and-establishing-relationships">
<h1>3. Importing data and establishing relationships<a class="headerlink" href="#importing-data-and-establishing-relationships" title="Permalink to this headline">¶</a></h1>
<p>After all data and documentation files are gathered and checked, import
the data files in the Editor. In the Metadata Editor, order the files
in a logical fashion (e.g., sequentially through sections).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are documenting a population census and have very large
data files, it is recommended to split the files by geographic area.
Typically, you will have a file at individual level, one at the
household level, and possibly one at the community level, for each
State or Province. In such case, import all files for one State or
Province only. You will import the other data files after you
complete the documentation of the files. This will considerably
reduce the time needed to save your files. The Metadata Editor will
allow you to replicate the metadata from the documented files to all
other data files that you will import later.</p>
</div>
<p>After all files are imported and ordered in a proper sequence, define
the key variables for each data file. The base key variable(s) in a data
file is (are) the variable(s) that provide the unique identifier of each
record in that specific data file.</p>
<p>Then establish the relations and validate them using the <em>Tool &gt;
Validate Dataset Relations</em> in the Editor. This automatic validation is
a way to check the structural integrity of the identifier variables and
assure there are no duplicates in the data.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Establishing relationships – An example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>In this example, we assume that the dataset is obtained from a
household budget survey and comprises:</p>
<ul class="simple">
<li><p>A household-level file “hhld.dat” with the household
characteristics (one record per household). Each household is
identified by a variable named <em>hhid</em>.</p></li>
<li><p>A household-level file “hhld.dat” with the household (one record
per person).Each household member is identified by the combination
of variables <em>hhid and memno</em>.</p></li>
<li><p>A consumption data file “cons.dat”, with one record per item
(goods and services) per household. Each record is uniquely
identified by the combination of variables <em>hhid</em> and <em>itemno</em>.
The file also contains a variable <em>district</em> identifying the
district where the household resides.</p></li>
<li><p>A data file “prices.dat” with average price per commodity, per
district (one record per item per district). Each record is
uniquely identified by variables <em>district</em> and <em>itemno</em>.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><img alt="_images/image5.png" src="_images/image5.png" />
</td>
</tr>
<tr class="row-even"><td><p>In the Metadata Editor, these relationships will be established as
follows in the “Key variables and relationships” section of each
data file:</p></td>
</tr>
<tr class="row-odd"><td><img alt="_images/Page21.png" src="_images/Page21.png" />
</td>
</tr>
</tbody>
</table>
<p>If you have imported your data from any format other than fixed ASCII,
re-sequence the data using the <em>Variables</em> &gt; <em>Resequence</em> option in the
Editor. This re-sequencing tool will automatically fill the “StartCol”
and “EndCol” columns in the variable description section. This must be
done for each data file.</p>
<img alt="_images/Page22.png" src="_images/Page22.png" />
<p>Before going further, quickly browse all variables in all data files to
visually check the frequencies. This will allow you to easily spot some
outliers or invalid codes, which will require recoding (which can be
done in the Editor or in the source data files which will then have to
be re-imported).</p>
<img alt="_images/Page22_2.png" src="_images/Page22_2.png" />
<p>Save the project. The Editor saves the full project, the associated data
and documentation in one zip file. We recommend you save the project using
the survey abbreviation, year and version number as project name
(e.g., UGA_2018_HIES_v01_M). Note that it is good practice to avoid using
spaces in a file name (use underscore characters instead).</p>
</div>
<div class="section" id="importing-external-resources">
<h1>4. Importing external resources<a class="headerlink" href="#importing-external-resources" title="Permalink to this headline">¶</a></h1>
<table class="docutils align-default">
<colgroup>
<col style="width: 41%" />
<col style="width: 33%" />
<col style="width: 26%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="3"><p>Before importing your external resources, create folders in the Editor
as necessary (these are directories in the External Resources section
in the Editor, not new directories on your hard drive). If you have
very few external resources, all resources can be listed in the root
directory. If you have many, organize them by type of resources (in the
example below, we have created separate directories for the
Questionnaires, Technical Documents, Computer Programs, Reports,
Tables, Photos and Maps).</p></td>
</tr>
<tr class="row-even"><td><img alt="_images/image11.png" src="_images/image11.png" />
</td>
<td colspan="2"><p>Create an entry for each resource by
entering a label in the Resource</p>
<p>Information field. This label should be
short but explicit. Then identify the</p>
<p>resource file in the  “Resource” field.
The field “Resource” is used to indicate</p>
<p>the filename or URL location (website) of
the external resource. The resource</p>
<p>consists of the filename, and a relative
path. The reason for entering a relative</p>
<p>path is that it will allow you to move
the whole study directory and its</p>
<p>subdirectories to another location or
another drive, without having to re-enter</p>
<p>the location of the files.</p>
</td>
</tr>
<tr class="row-odd"><td colspan="3"><p>Example:</p>
<p>Let’s assume your study is a Household Budget Survey conducted in 2018.
If you followed the recommendations made in the introductory chapter
“Before you start – Organizing your files”, you will have created a
directory like C:UGA_2018_HIES. Suppose also that a document titled
Report2018.pdf is saved in a directory C:UGA_2018_HIESDoc. When you
fill the resource field in the External Resources page, do NOT enter
“C:UGA_2018_HIESDocReport2018.pdf.pdf. Enter the file name as
follows: DocReportsReport2018.pdf</p>
<img alt="_images/Page22_3.png" src="_images/Page22_3.png" />
</td>
</tr>
</tbody>
</table>
<p>Some resources might be composed of more than one file (for example, the
CSPro data entry application includes multiple files that should not be
separated). In such cases, zip them into one single file, and import it
as a single resource.</p>
<p>For documents available in multiple formats (for example, a
questionnaire available in Excel and in PDF), you may create two
separate resources, or zip the files into one single file. In such case,
list the different formats available in the “Content/ Description”
field.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><em>Best Practices – Naming Convention for External Resources</em></p>
<ul class="simple">
<li><p>Use file names short, but self-explanatory about the content of
the document.</p></li>
<li><p>Preferably, use lower cases.</p></li>
<li><p>Avoid spaces to delimit words.</p></li>
<li><p>Be consistent with your method of naming across all files. For
instance, if you use underscores to delimit words, keep it that
way in all files.</p></li>
<li><p>Use only alphanumeric characters, underscores or dashes. Avoid
using special characters (!&#64;#$%^&amp;*()~) or any accented characters.</p></li>
<li><p>If you intend to have an archive useable and downloadable across
multiple countries, use English names for your files.</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="completing-metadata">
<h1>5. Completing metadata<a class="headerlink" href="#completing-metadata" title="Permalink to this headline">¶</a></h1>
<p>The Metadata Editor makes use of the Data Documentation Initiative
(DDI Version 2.5), the Dublin Core (DCMI version X) metadata standards
and ISO 19139 for geospatial information.</p>
<p>The table below provides an overview of the different metadata standards
as related to the project. Each metadata standard is integrated into the
template that will define the project.</p>
<img alt="_images/Page23.png" src="_images/Page23.png" />
<p>A thorough completion of the DDI and DCMI elements will significantly
raise the value of the archiving work by providing users with the
necessary information to put the study into its proper context and to
understand its purpose.</p>
<p>The DDI requires completion of the following sections: Document
Description, Study Description, Datasets, Variables Groups, and
External Resources. Recommendations for each field included in the
IHSN template are provided below.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>The IHSN recommends using the standardized IHSN DDI/DCMI templates
(Study Template and External Resources Template). This Quick
Reference Guide is based on these two templates. Visit the IHSN
website to download the latest version of these templates,
available in multiple languages.</p></td>
</tr>
</tbody>
</table>
<p><strong>Overall recommendations:</strong></p>
<ul class="simple">
<li><p>As an archivist, you may need to seek assistance from key experts
involved in some of the technical aspects of the survey.</p></li>
<li><p>As a general rule, avoid using ALL CAPS when you fill DDI fields.
Also, check the spelling of all entries. The Editor does not provide
(yet) an automatic spell checker.</p></li>
<li><p>Some of the examples below present an optimal documentation of some
fields. In many cases, for past surveys, you will not find such
detailed information. Try to provide as much detail as possible. For
future surveys, the information should be compiled and provided
during the whole life cycle of the survey. This will ensure that the
best possible documentation is available at completion of that
survey.</p></li>
</ul>
<div class="section" id="good-practices-for-completing-the-document-description">
<h2>5.1. Good practices for completing the Document Description<a class="headerlink" href="#good-practices-for-completing-the-document-description" title="Permalink to this headline">¶</a></h2>
<p>Documenting a study using the DDI and DCMI metadata standards consists
of generating a metadata file which will be saved in XML format in what
is called an <em>XML Document</em>. The <em>Document Description</em> described below
is a description of that XML file. The IHSN Template selected 4 elements
to describe the DDI document.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 51%" />
<col style="width: 23%" />
<col style="width: 26%" />
</colgroup>
<tbody>
<tr class="row-odd"><td rowspan="4"><p>Metadata Producer</p></td>
<td colspan="2"><p>Name of the person(s) or
organization(s) who documented
the dataset. Use the “role”
attribute to distinguish
different stages of involvement
in the production process.</p>
<p>Example:</p>
</td>
</tr>
<tr class="row-even"><td><p><em>Name</em></p></td>
<td><p><em>Role</em></p></td>
</tr>
<tr class="row-odd"><td><p><em>National
Statistics
Office
(NSO)</em></p></td>
<td><p><em>Documentation
of the
study</em></p></td>
</tr>
<tr class="row-even"><td><p><em>International
Household
Survey
Network
(IHSN)</em></p></td>
<td><p><em>Review of
the
metadata</em></p></td>
</tr>
<tr class="row-odd"><td><p>Date of Production</p></td>
<td colspan="2"><p>This is the date (in ISO format
YYYY-MM-DD) the DDI document was
produced (not distributed or
archived). This date will be
automatically imputed when you
save the file.</p></td>
</tr>
<tr class="row-even"><td><p>DDI Document Version</p></td>
<td colspan="2"><p>Documenting a dataset is not a
trivial exercise. Producing
“perfect” metadata is probably
impossible. It may therefore
happen that, having identified
errors in a DDI document or
having received suggestions for
improvement, you decide to modify
the Document even after a first
version has been disseminated.
This element is used to identify
and describe the current version
of the document. It is good
practice to provide a version
number (and date), and
information on what distinguishes
this version from the previous
one(s) if relevant.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>Version 02 (July 2017). This
version is identical to version
01, except for the section on
Data Appraisal which was
updated.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>DDI Document ID Number</p></td>
<td colspan="2"><p>The ID number of a DDI document
is a unique number that is used
to identify this DDI file. Define
and use a consistent scheme to
use. Such an ID could be
constructed as follows:
DDI_COUNTRY_PRODUCER_SURVEY_YEAR
where</p>
<ul class="simple">
<li><p><em>country</em> is the 3-letter ISO
country abbreviation</p></li>
<li><p><em>producer</em> is the abbreviation
of the producing agency</p></li>
<li><p><em>survey</em> is the survey
abbreviation</p></li>
<li><p><em>year</em> is the reference year
(or the year the survey
started)</p></li>
<li><p>DDI document version number</p></li>
</ul>
<dl class="simple">
<dt>Example:</dt><dd><p><em>The DDI file related to the
Demographic and Health Survey
documented by staff from the
Uganda Bureau of Statistics in
2005 would have the following
ID:
DDI_UGA_UBOS_DHS_2005_v01. If
the same survey is documented by
a staff from the IHSN, this
would be
DDI_UGA_IHSN_DHS_205_v01.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Collection</p></td>
<td colspan="2"><p>This field allows viewed and
searched the study by collection</p></td>
</tr>
<tr class="row-odd"><td><p>Programs</p></td>
<td colspan="2"><p>Link surveys to projects / trust
funds</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="good-practices-for-completing-the-study-description">
<h2>5.2. Good practices for completing the Study Description<a class="headerlink" href="#good-practices-for-completing-the-study-description" title="Permalink to this headline">¶</a></h2>
<p>In the DDI standard, the Study Description is the section that contains
all elements needed to describe the study itself (investigators, dates
and methods, scope and coverage, etc.)</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="2"><p><strong>Identification</strong></p></td>
</tr>
<tr class="row-even"><td><p>Survey Title</p></td>
<td><p>The title is the official name of
the survey as it is stated on the
questionnaire or as it appears in
the design documents. The
following items should be noted:</p>
<ul class="simple">
<li><p>Include the reference year(s)
of the survey in the title.</p></li>
<li><p>Do not include the
abbreviation of the survey
name in the title.</p></li>
<li><p>As the survey title is a
proper noun, the first letter
of each word should be
capitalized (except for
prepositions or other
conjunctions).</p></li>
<li><p>Including the country name in
the title is optional.</p></li>
</ul>
<dl class="simple">
<dt>Example:</dt><dd><ul class="simple">
<li><p><em>National Household Budget
Survey 2012-2013</em></p></li>
<li><p><em>Popstan Multiple Indicator
Cluster Survey 2012</em></p></li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Survey Subtitle</p></td>
<td><p>Subtitle is optional and rarely
used. A subtitle can be used to
add information usually
associated with a sequential
qualifier for a survey.</p>
<dl>
<dt>Example:</dt><dd><p><em>Title: Welfare Monitoring
Survey 2007</em></p>
<p><em>Subtitle: Fifth round</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Abbreviation or Acronym</p></td>
<td><p>The abbreviation of a survey is
usually the first letter of each
word of the titled survey. The
survey reference year(s) may be
included.</p>
<dl class="simple">
<dt>Example:</dt><dd><ul class="simple">
<li><p><em>DHS 2015 for “Demographic and
Health Survey 2005”</em></p></li>
<li><p><em>HIES 2012-2013 for “Household
Income and Expenditure Survey
2003”</em></p></li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Study type</p></td>
<td><p>The study type or <em>survey type</em>
is the broad category defining
the survey. This item has a
controlled vocabulary (you may
customize the IHSN template to
adjust this controlled vocabulary
if needed).</p></td>
</tr>
<tr class="row-even"><td><p>Series information</p></td>
<td><p>A survey may be repeated at
regular intervals (such as an
annual labour force survey), or
be part of an international
survey program (such as the MICS,
CWIQ, DHS, LSMS and others). The
Series information is a
description of this “collection”
of surveys. A brief description
of the characteristics of the
survey, including when it
started, how many rounds were
already implemented, and who is
in charge would be provided here.
If the survey does not belong to
a series, leave this field empty.</p>
<dl>
<dt>Example:</dt><dd><p><em>The Multiple Indicator Cluster
Survey, Round 3 (MICS3) is the
third round of MICS surveys,
previously conducted around 1995
(MICS1) and 2000 (MICS2). MICS
surveys are designed by UNICEF,
and implemented by national
agencies in participating
countries. MICS was designed to
monitor various indicators
identified at the World Summit
for Children and the Millennium
Development Goals.
Many questions and indicators in
MICS3 are consistent and
compatible with the prior round
of MICS (MICS2) but less so with
MICS1, although there have been a
number of changes in definition
of indicators between rounds.</em></p>
<p><em>Round 1 covered X countries,
round 2 covered Y countries, and
Round Z covered N countries.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Translated title</p></td>
<td><p>In countries with more than one
official language, a translation
of the title may be provided.
Likewise, the translated title
may simply be a translation into
English from a country’s own
language. Special characters
should be properly displayed
(such as accents and other stress
marks or different alphabets).</p></td>
</tr>
<tr class="row-even"><td><p>Unique user defined ID Number</p></td>
<td><p>The ID number of a dataset is a
unique number that is used to
identify a particular survey.
Define and use a consistent
scheme to use. Such an ID could
be constructed as follows:
country-producer-survey-year-vers
ion
where</p>
<ul class="simple">
<li><p><em>country</em> is the 3-letter ISO
country abbreviation</p></li>
<li><p><em>producer</em> is the abbreviation
of the producing agency</p></li>
<li><p><em>survey</em> is the survey
abbreviation</p></li>
<li><p><em>year</em> is the reference year
(or the year the survey
started)</p></li>
<li><p><em>version</em> is the number
dataset version number (see
Version Description below)</p></li>
</ul>
<dl>
<dt>Example:</dt><dd><p><em>The Demographic and Health
Survey implemented by the Uganda
Bureau of Statistics in 2005
could have the following ID:</em></p>
<p><em>UGA-UBOS-DHS-2005-v01.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Depositor</p></td>
<td><p>The name of the person
(or institution) who provided this
data collection to the archive
storing it.</p></td>
</tr>
<tr class="row-even"><td><p>Date of Deposit</p></td>
<td><p>The date that the data collection
was deposited with the archive that
originally received it.</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Version</strong></p></td>
</tr>
<tr class="row-even"><td><p>Version Description</p></td>
<td><p>The version description should
contain a version number followed
by a version label. The version
number should follow a standard
convention to be adopted by the
institute. We recommend that
larger series be defined by a
number to the left of a decimal
and iterations of the same series
by a sequential number that
identifies the release. Larger
series will typically include (0)
the raw, unedited dataset; (1)
the edited dataset, non
anonymized, for internal use at
the data producing agency; and
(2) the edited dataset, prepared
for dissemination to secondary
users (possibly anonymized).</p>
<dl class="simple">
<dt>Example:</dt><dd><ul class="simple">
<li><p><em>v00: Basic raw data,
obtained from data entry
(before editing)</em>.</p></li>
<li><p><em>v01: Edited data, second
version, for internal use
only</em>.</p></li>
<li><p><em>v02: Edited, anonymous
dataset for public
distribution</em>.</p></li>
</ul>
</dd>
</dl>
<p>A brief description of the version
should follow the numerical
identification.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Production date</p></td>
<td><p>This is the date in ISO format
(yyyy-mm-dd) of actual and final
production of the data.
Production dates of all versions
should be carefully tracked.
Provide at least the month and
year. Use the calendar icon in
the Metadata editor to assure
that the date selected is in
compliance with the ISO format.</p></td>
</tr>
<tr class="row-even"><td><p>Version Notes</p></td>
<td><p>Version notes should provide a
brief report on the changes made
through the versioning process.
The note should indicate how this
version differs from other
versions of the same dataset.</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Study Authorization</strong></p></td>
</tr>
<tr class="row-even"><td><p>Authorizing Agency</p></td>
<td><p>Name of the agent or agency that
authorized the study. The
“affiliation” attribute indicates
the institutional affiliation of
the authorizing agent or agency.
The “abbr” attribute holds the
abbreviation of the authorizing
agent’s or agency’s name</p></td>
</tr>
<tr class="row-odd"><td><p>Authorization Statement</p></td>
<td><p>The text of the authorization. Use
XHTML to capture significant
structure in the document</p>
<p>Example:</p>
<p>Required documentation covering
the study purpose, disclosure
information, questionnaire
content, and consent statements
was delivered to the OUHS on
2010-10-01 and reviewed by the
compliance officer. Statement of
authorization for the described
study was received on 2010-11-04</p>
</td>
</tr>
<tr class="row-even"><td><p>Legal basis</p></td>
<td><p>Decree or law authorizing or
requiring the study
(e.g. census act)</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Overview</strong></p></td>
</tr>
<tr class="row-even"><td><p>Study Budget</p></td>
<td><p>Describe the budget of the project
in as much detail as needed.
Internal structure is allowed using
XHTML elements. Different
organizations express their budgets
in different formats and this open
format allows flexibility.</p>
<p>Attributes: Budget line ID, Budget
line label, Amount, Currency and
Source of funding.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Abstract</p></td>
<td><p>The abstract should provide a
clear summary of the purposes,
objectives and content of the
survey. It should be written by a
researcher or survey statistician
aware of the survey.</p></td>
</tr>
<tr class="row-even"><td><p>Objectives of the study</p></td>
<td><p>Describe the Main (explicit) and
secondary (explicit) objectives of
the survey.</p></td>
</tr>
<tr class="row-odd"><td><p>Kind of data</p></td>
<td><p>This field is a broad
classification of the data and it
is associated with a drop-down
box providing controlled
vocabulary. That controlled
vocabulary includes 9 items but
is not limited to them.</p></td>
</tr>
<tr class="row-even"><td><p>Unit of analysis</p></td>
<td><p>A survey could have various units
of analysis. These are fairly
standard and are usually:</p>
<ul class="simple">
<li><p>Household (household survey,
census)</p></li>
<li><p>Person (household survey,
census)</p></li>
<li><p>Enterprise (enterprise survey)</p></li>
<li><p>Commodity (household survey,
price survey)</p></li>
<li><p>Plots of land (agricultural
survey)</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Scope</strong></p></td>
</tr>
<tr class="row-even"><td><p>Description of scope</p></td>
<td><p>The scope is a description of the
themes covered by the survey. It
can be viewed as a summary of the
modules that are included in the
questionnaire. The scope does not
deal with geographic coverage.</p>
<dl class="simple">
<dt>Example:</dt><dd><p>The scope of the Multiple
Indicator Cluster Survey
includes:</p>
<ul class="simple">
<li><p><em>HOUSEHOLD: Household
characteristics, household
listing, orphaned and
vulnerable children,
education, child labour, water
and sanitation, household use
of insecticide treated
mosquito nets, and salt
iodization, with optional
modules for child discipline,
child disability, maternal
mortality and security of
tenure and durability of
housing.</em></p></li>
<li><p><em>WOMEN: Women’s
characteristics, child
mortality, tetanus toxoid,
maternal and newborn health,
marriage, polygyny, female
genital cutting,
contraception, and HIV/AIDS
knowledge, with optional
modules for unmet need,
domestic violence, and sexual
behavior.</em></p></li>
<li><p><em>CHILDREN: Children’s
characteristics, birth
registration and early
learning, vitamin A,
breastfeeding, care of
illness, malaria,
immunization, and
anthropometry, with an
optional module for child
development.</em></p></li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Topic classifications</p></td>
<td><p>A topic classification
facilitates referencing and
searches in electronic survey
catalogs. Topics should be
selected from a standard
thesaurus, preferably an
international, multilingual
thesaurus. The IHSN recommends
the use of the thesaurus used by
the Council of European Social
Science Data Archives (CESSDA).
The CESSDA thesaurus has been
introduced as a controlled
vocabulary in the IHSN Study
Template version 1.3 (available
<a class="reference external" href="http://www.surveynetwork.org/toolkit">www.surveynetwork.org/toolkit</a>).</p></td>
</tr>
<tr class="row-even"><td><p>Keywords</p></td>
<td><p>Keywords summarize the content or
subject matter of the survey. As
topic classifications, these are
used to facilitate referencing
and searches in electronic survey
catalogs. Keywords should be
selected from a standard
thesaurus, preferably an
international, multilingual
thesaurus. Entering a list of
keywords is tedious. This option
is provided for advanced users
only.</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Quality Statement</strong></p></td>
</tr>
<tr class="row-even"><td><p>Standards Compliance</p></td>
<td><p>This section lists all specific
standards complied with during the
execution of this study. Note the
standard name and producer and how
the study complied with the
standard</p></td>
</tr>
<tr class="row-odd"><td><p>Other Quality Statement</p></td>
<td><p>Enter any additional quality
statements</p></td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Post Evaluation Procedures</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Evaluator Type</p></td>
<td><p>The evaluator element identifies
persons or organizations involved
in the evaluation. The Affiliation
attribute contains the affiliation
of the individual or organization.
The Abbr. attribute holds an
abbreviation for the individual or
organization. The Role attribute
indicates the role played by the
individual or organization in the
evaluation process.</p>
<p>Example:</p>
<ul class="simple">
<li><p>Affiliation: United Nations</p></li>
<li><p>Abbr.: UNSD</p></li>
<li><p>Role: Consultant</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p>Evaluation Process</p></td>
<td><p>Describes the evaluation process
followed. Ex-Post Evaluations are
frequently done within large
statistical or research agencies,
in particular when the survey is
intended to be repeated or on-going</p></td>
</tr>
<tr class="row-odd"><td><p>Evaluation Outcomes</p></td>
<td><p>Describe the outcomes of the
evaluation</p></td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Coverage</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Country</p></td>
<td><p>Enter the country name, even in
cases where the survey did not
cover the entire country. In the
field “Abbreviation”, we
recommend that you enter the
3-letter ISO code of the country.
If the dataset you document
covers more than one country,
enter all in separate rows.</p></td>
</tr>
<tr class="row-even"><td><p>Geographic coverage</p></td>
<td><p>This filed aims at describing at
what geographic level the data
are representative. Typical
entries will be “National
coverage”, “Urban (or rural)
areas only”, “state of …”,
“Capital city”, etc.</p>
<p>Note that we do not describe here
where the data was collected. For
example, as sample survey could
be declared as “national
coverage” even in cases where
some districts where not included
in the sample, as long as the
sampling strategy was such that
the representativity is national.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Geographic Unit</p></td>
<td><p>Lowest level of geographic
aggregation covered by the data.</p></td>
</tr>
<tr class="row-even"><td><p>Universe</p></td>
<td><p>We are interested here in the
survey universe (not the universe
of particular sections of the
questionnaires or variables),
i.e. in the identification of the
population of interest in the
survey. The universe will rarely
be the entire population of the
country. Sample household
surveys, for example, usually do
not cover homeless, nomads,
diplomats, community households.
Population censuses do not cover
diplomats. Try to provide the
most detailed information
possible on the population
covered by the survey/census.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>The survey covered all de jure
household members (usual
residents), all women aged 15-49
years resident in the household,
and all children aged 0-4 years
(under age 5) resident in the
household.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Geographic bounding box</p></td>
<td><p>The geographic bounding box is the
minimum box, defined by west and
east longitudes and north and south
latitudes, that includes the
largest geographic extent of the
dataset’s geographic coverage.
This element is used in the first
pass of a coordinate-based search.
If the Geographic bounding Polygon
element is included, then this
field element MUST be included</p></td>
</tr>
<tr class="row-even"><td><p>Geographic Bounding Polygon</p></td>
<td><p>This field allows the creation of
multiple polygons to describe in a
more detailed manner the geographic
area covered by the dataset. It
should only be used to define the
outer boundaries of a covered area.</p>
<p>Example:
In the United States, such polygons
can be created to define boundaries
for Hawaii, Alaska, and the
continental United States, but not
interior boundaries for the
contiguous states. This field is
used to refine a coordinate-based
search, not to actually map an area</p>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Producers and Sponsors.</strong></p></td>
</tr>
<tr class="row-even"><td><p>Authoring Entity/Primary
investigators</p></td>
<td><p>The primary investigator will in
most cases be an institution, but
could also be an individual in
the case of small-scale academic
surveys. The two fields to be
completed are the Name and the
Affiliation fields. Generally, in
a survey, the Primary
Investigator will be the
institution implementing the
survey. If various institutions
have been equally involved as
main investigators, then all
should be mentioned. This only
includes the agencies responsible
for the implementation of the
survey, not its funding or
technical assistance. The order
in which they are listed is
discretionary. It can be
alphabetic or by significance of
contribution. Individual persons
can also be mentioned. If persons
are mentioned use the appropriate
format of Surname, First name.</p></td>
</tr>
<tr class="row-odd"><td><p>Producers</p></td>
<td><p>This field is provided to list
other interested parties and
persons that have played a
significant but not the leading
technical role in implementing
and producing the data. The
specific fields to be competed
are: Name of the organization,
Abbreviation, Affiliation and
Role. If any of the fields are
not applicable these can be left
blank. The abbreviations should
be the official abbreviation of
the organization. The role should
be a short and succinct phrase or
description on the specific
assistance provided by the
organization in order to produce
the data. The roles should be
standard vocabulary such as:</p>
<ul class="simple">
<li><p>[Technical assistance in]
questionnaire design</p></li>
<li><p>[Technical assistance in]
sampling methodology /
selection</p></li>
<li><p>[Technical assistance in] data
collection</p></li>
<li><p>[Technical assistance in] data
processing</p></li>
<li><p>[Technical assistance in] data
analysis</p></li>
</ul>
<p>Do not include here the financial
sponsors.</p>
</td>
</tr>
<tr class="row-even"><td><p>Funding Agency/Sponsor</p></td>
<td><p>List the organizations (national
or international) that have
contributed, in cash or in kind,
to the financing of the survey.
The government institution that
has provided funding should not
be forgotten.</p></td>
</tr>
<tr class="row-odd"><td><p>Other Identifications/
acknowledgements</p></td>
<td><p>This optional field can be used
to acknowledge any other people
and institutions that have in
some form contributed to the
survey.</p></td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Sampling</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Sampling procedure</p></td>
<td><p>This field only applies to sample
surveys. Information on sampling
procedure is crucial (although
not applicable for censuses and
administrative datasets). This
section should include summary
information that includes though
is not limited to:</p>
<ul class="simple">
<li><p>Sample size</p></li>
<li><p>Selection process (e.g.,
probability proportional to
size or over sampling)</p></li>
<li><p>Stratification (implicit and
explicit)</p></li>
<li><p>Stages of sample selection</p></li>
<li><p>Design omissions in the sample</p></li>
<li><p>Level of representation</p></li>
<li><p>Strategy for absent
respondents/not found/refusals
(replacement or not)</p></li>
<li><p>Sample frame used, and listing
exercise conducted to update
it</p></li>
</ul>
<p>It is useful also to indicate
here what variables in the data
files identify the various levels
of stratification and the primary
sample unit. These are crucial to
the data users who want to
properly account for the sampling
design in their analyses and
calculations of sampling errors.</p>
<p>This section accepts only text
format; formulae cannot be
entered. In most cases, technical
documents will exist that
describe the sampling strategy in
detail. In such cases, include
here a reference
(title/author/date) to this
document, and make sure that the
document is provided in the
External Resources.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>5000 households were selected
for the sample. Of these, 4996
were occupied households and 4811
were successfully interviewed for
a response rate of 96.3%. Within
these households, 7815 eligible
women aged 15-49 were identified
for interview, of which 7505 were
successfully interviewed
(response rate 96.0%), and 3242
children aged 0-4 were identified
for whom the mother or caretaker
was successfully interviewed for
3167 children (response rate
97.7%). These give overall
response rates (household
response rate times individual
response rate) for the women’s
interview of 92.5% and for the
children’s interview of 94.1%.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Sample Frame Name</p></td>
<td><p>Sample frame describes the sampling
frame used for identifying the
population from which the sample
was taken. Label and text
describing the sample frame</p></td>
</tr>
<tr class="row-odd"><td><p>Update of listing</p></td>
<td><p>Describes operations conducted to
update the sample frame</p></td>
</tr>
<tr class="row-even"><td><p>Valid Period</p></td>
<td><p>Defines a time period for the
validity of the sampling frame.
Enter dates in YYYY-MM-DD format.</p></td>
</tr>
<tr class="row-odd"><td><p>Custodian</p></td>
<td><p>Custodian identifies the agency or
individual who is responsible for
creating or maintaining the sample
frame. Attribute affiliation
provides the affiliation of the
custodian with an agency or
organization. Attribute abbr.
provides an abbreviation for the
custodian.</p></td>
</tr>
<tr class="row-even"><td><p>Use Statement</p></td>
<td><p>Sample frame use statement</p></td>
</tr>
<tr class="row-odd"><td><p>Frame Unit</p></td>
<td><p>Provides information about the
sampling frame unit. The attribute
“is Primary” is boolean, indicating
whether the unit is primary or not.</p></td>
</tr>
<tr class="row-even"><td><p>Reference Period</p></td>
<td><p>Indicates the period of time in
which the sampling frame was
actually used for the study in
question. Use ISO 8601 date/time
formats to enter the relevant
date(s).</p></td>
</tr>
<tr class="row-odd"><td><p>Sample Size</p></td>
<td><p>This element provides the targeted
sample size in integer format.</p>
<p>Attributes: Planned / Actual and
Unit and Number.</p>
</td>
</tr>
<tr class="row-even"><td><p>Sample Size Formula</p></td>
<td><p>This element includes the formula
that was used to determine the
sample size</p></td>
</tr>
<tr class="row-odd"><td><p>Stratification</p></td>
<td><p>Describe the Stratification
(implicit and explicit) and the
Variables identifying strata and
PSU</p></td>
</tr>
<tr class="row-even"><td><p>Deviation from sample design</p></td>
<td><p>This field only applies to sample
surveys.</p>
<p>Sometimes the reality of the
field requires a deviation from
the sampling design (for example
due to difficulty to access to
zones due to weather problems,
political instability, etc). If
for any reason, the sample design
has deviated, this should be
reported here.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Response rate</p></td>
<td><p>Response rate provides that
percentage of households (or
other sample unit) that
participated in the survey based
on the original sample size.
Omissions may occur due to
refusal to participate,
impossibility to locate the
respondent, or other. Sometimes,
a household may be replaced by
another by design. Check that the
information provided here is
consistent with the sample size
indicated in the “Sampling
procedure field” and the number
of records found in the dataset
(for example, if the sample
design mention a sample of 5,000
households and the data on
contain data on 4,500 households,
the response rate should not be
100 percent).</p>
<p>Provide if possible the response
rates by stratum. If information
is available on the causes of
non-response (refusal/not
found/other), provide this
information as well.</p>
<p>This field can also in some cases
be used to describe non-responses
in population censuses.</p>
</td>
</tr>
<tr class="row-even"><td><p>Weighting</p></td>
<td><p>This field only applies to sample
surveys.</p>
<p>Provide here the list of
variables used as weighting
coefficient. If more than one
variable is a weighting variable,
describe how these variables
differ from each other and what
the purpose of each one of them
is.</p>
<dl>
<dt>Example:</dt><dd><p><em>Sample weights were calculated
for each of the data files.</em></p>
<p><em>Sample weights for the household
data were computed as the inverse
of the probability of selection
of the household, computed at the
sampling domain level
(urban/rural within each region).
The household weights were
adjusted for non-response at the
domain level, and were then
normalized by a constant factor
so that the total weighted number
of households equals the total
unweighted number of households.
The household weight variable is
called HHWEIGHT and is used with
the HH data and the HL data.</em></p>
<p><em>Sample weights for the women’s
data used the un-normalized
household weights, adjusted for
non-response for the women’s
questionnaire, and were then
normalized by a constant factor
so that the total weighted number
of women’s cases equals the total
unweighted number of women’s
cases.</em></p>
<p><em>Sample weights for the
children’s data followed the same
approach as the women’s and used
the un-normalized household
weights, adjusted for
non-response for the children’s
questionnaire, and were then
normalized by a constant factor
so that the total weighted number
of children’s cases equals the
total unweighted number of
children’s cases.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Data Collection</strong></p></td>
</tr>
<tr class="row-even"><td><p>Dates of data collection</p></td>
<td><p>Enter the dates (at least month
and year) of the start and end of
the data collection. They should
be in the standard ISO format of
YYYY-MM-DD.</p>
<p>In some cases, data collection
for a same survey can be
conducted in waves. In such case,
you should enter the start and
end date of each wave separately,
and identify each wave in the
“cycle” field.</p>
</td>
</tr>
<tr class="row-odd"><td><p>Collector Training</p></td>
<td><p>Describes the training provided to
data collectors including
interviewer training, process
testing, compliance with standards
etc. This is repeatable for
language and to capture different
aspects of the training process.
The type attribute allows
specification of the type of
training being described</p></td>
</tr>
<tr class="row-even"><td><p>Frequency of Data Collection</p></td>
<td><p>For data collected at more than one
point in time, the frequency with
which the data were collected. The
“freq” attribute is included to
permit the development of a
controlled vocabulary for this
element.</p></td>
</tr>
<tr class="row-odd"><td><p>Time period</p></td>
<td><p>This field will usually be left
empty. Time period differs from
the dates of collection as they
represent the period for which
the data collected are applicable
or relevant.</p></td>
</tr>
<tr class="row-even"><td><p>Data Sources</p></td>
<td><p>Used to list the book(s),
article(s), serial(s), and/or
machine-readable data file(s)–if
any–that served as the source(s)
of the data collection</p></td>
</tr>
<tr class="row-odd"><td><p>Alternatives to data collection</p></td>
<td><p>Sources of data available /
potentially considered</p></td>
</tr>
<tr class="row-even"><td><p>Mode of data collection</p></td>
<td><p>The mode of data collection is
the manner in which the interview
was conducted or information was
gathered. This field is a
controlled vocabulary field. Use
the drop-down button in the
Toolkit to select one option. In
most cases, the response will be
“face to face interview”. But for
some specific kinds of datasets,
such as for example data on rain
falls, the response will be
different.</p></td>
</tr>
<tr class="row-odd"><td><p>Data Capture</p></td>
<td><p>Where was data capture done (e.g.,
In the field or at the office) and
when was data capture done. Also,
describe the technology using for
data capture (e.g. scanning, PDAs
OR Web)</p></td>
</tr>
<tr class="row-even"><td><p>Notes on data collection</p></td>
<td><p>This element is provided in order
to document any specific
observations, occurrences or
events during data collection.
Consider stating such items like:</p>
<ul class="simple">
<li><p>Was a training of enumerators
held? (elaborate)</p></li>
<li><p>Any events that could have a
bearing on the data quality?</p></li>
<li><p>How long did an interview take
on average?</p></li>
<li><p>Was there a process of
negotiation between
households, the community and
the implementing agency?</p></li>
<li><p>Are anecdotal events recorded?</p></li>
<li><p>Have the field teams
contributed by supplying
information on issues and
occurrences during data
collection?</p></li>
<li><p>In what language was the
interview conducted?</p></li>
<li><p>Was a pilot survey conducted?</p></li>
<li><p>Were there any corrective
actions taken by management
when problems occurred in the
field?</p></li>
</ul>
<dl>
<dt>Example:</dt><dd><p><em>The pre-test for the survey took
place from August 15, 2006 -
August 25, 2006 and included 14
interviewers who would later
become supervisors for the main
survey.</em></p>
<p><em>Each interviewing team comprised
of 3-4 female interviewers (no
male interviewers were used due
to the sensitivity of the subject
matter), together with a field
editor and a supervisor and a
driver. A total of 52
interviewers, 14 supervisors and
14 field editors were used. Data
collection took place over a
period of about 6 weeks from
September 2, 2006 until October
17, 2006. Interviewing took place
everyday throughout the fieldwork
period, although interviewing
teams were permitted to take one
day off per week.</em></p>
<p><em>Interviews averaged 35 minutes
for the household questionnaire
(excluding salt testing), 23
minutes for the women’s
questionnaire, and 27 for the
under five children’s
questionnaire (excluding the
anthropometry). Interviews were
conducted primarily in English
and Mumbo-jumbo, but occasionally
used local translation in
double-Dutch, when the respondent
did not speak English or
Mumbo-jumbo.</em></p>
<p><em>Six staff members of GenCenStat
provided overall fieldwork
coordination and supervision. The
overall field coordinator was
Mrs. Doe.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Questionnaires</p></td>
<td><p>This element is provided to
describe the questionnaire(s)
used for the data collection. The
following should be mentioned:</p>
<ul class="simple">
<li><p>List of questionnaires and
short description of each (all
questionnaires must be
provided as External
Resources)</p></li>
<li><p>In what language were the
questionnaires published?</p></li>
<li><p>Information on the
questionnaire design process
(based on a previous
questionnaire, based on a
standard model questionnaire,
review by stakeholders). If a
document was compiled that
contains the comments provided
by the stakeholders on the
draft questionnaire, or a
report prepared on the
questionnaire testing, a
reference to these documents
should be provided here and
the documents should be
provided as External
Resources.</p></li>
</ul>
<dl>
<dt>Example:</dt><dd><p><em>The questionnaires for the
Generic MICS were structured
questionnaires based on the MICS3
Model Questionnaire with some
modifications and additions. A
household questionnaire was
administered in each household,
which collected various
information on household members
including sex, age, relationship,
and orphanhood status. The
household questionnaire includes
household characteristics,
support to orphaned and
vulnerable children, education,
child labour, water and
sanitation, household use of
insecticide treated mosquito
nets, and salt iodization, with
optional modules for child
discipline, child disability,
maternal mortality and security
of tenure and durability of
housing.</em></p>
<p><em>In addition to a household
questionnaire, questionnaires
were administered in each
household for women age 15-49 and
children under age five. For
children, the questionnaire was
administered to the mother or
caretaker of the child.</em></p>
<p><em>The women’s questionnaire
include women’s characteristics,
child mortality, tetanus toxoid,
maternal and newborn health,
marriage, polygyny, female
genital cutting, contraception,
and HIV/AIDS knowledge, with
optional modules for unmet need,
domestic violence, and sexual
behavior.</em></p>
<p><em>The children’s questionnaire
includes children’s
characteristics, birth
registration and early learning,
vitamin A, breastfeeding, care of
illness, malaria, immunization,
and anthropometry, with an
optional module for child
development.</em></p>
<p><em>The questionnaires were
developed in English from the
MICS3 Model Questionnaires, and
were translated into Mumbo-jumbo.
After an initial review the
questionnaires were translated
back into English by an
independent translator with no
prior knowledge of the survey.
The back translation from the
Mumbo-jumbo version was
independently reviewed and
compared to the English original.
Differences in translation were
reviewed and resolved in
collaboration with the original
translators.</em></p>
<p><em>The English and Mumbo-jumbo
questionnaires were both piloted
as part of the survey pretest.</em></p>
<p><em>All questionnaires and modules
are provided as external
resources.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Instrument Development</p></td>
<td><p>Describe any development work on
the data collection instrument.
Type attribute allows for the
optional use of a defined
development type with or without
use of a controlled vocabulary.</p></td>
</tr>
<tr class="row-odd"><td><p>Review process for survey
instrument</p></td>
<td><p>Description of the review process /
list of agencies/people consulted</p></td>
</tr>
<tr class="row-even"><td><p>Pilot/testing of survey instrument
and data collection</p></td>
<td><p>Description of pilot survey</p></td>
</tr>
<tr class="row-odd"><td><p>Survey management team</p></td>
<td><p>Attributes: Name, Tittle, Agency,
Role</p></td>
</tr>
<tr class="row-even"><td><p>Data collectors</p></td>
<td><p>This element is provided in order
to record information regarding
the persons and/or agencies that
took charge of the data
collection. This element includes
3 fields: Name, Abbreviation,
the Affiliation and the Role. In
most cases, we will record here the
name of the agency, not the name of
interviewers. Only in the case of
very small-scale surveys, with a
very limited number of
interviewers, the name of person
will be included as well. The
field Affiliation is optional and
not relevant in all cases. The role
attribute specifies the role of
person in the data collection
process.</p>
<dl>
<dt>Example:</dt><dd><p><em>Abbreviation: CSO</em></p>
<p><em>Affiliation: Ministry of
Planning</em></p>
<p><em>Role: Planner</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Compliance with international data
collection standards</p></td>
<td><p>Describe if the survey comply with
international survey
recommendations</p></td>
</tr>
<tr class="row-even"><td><p>Supervision</p></td>
<td><p>This element will provide
information on the oversight of
the data collection. The
following should be considered:</p>
<ul class="simple">
<li><p>Were the enumerators organized
in teams that included a
controller and a supervisor?
With how many
controllers/supervisors per
interviewer?</p></li>
<li><p>What were the main roles of
the controllers/supervisors?</p></li>
<li><p>Were there visits to the field
by upper management? How
often?</p></li>
</ul>
<dl>
<dt>Example:</dt><dd><p><em>Interviewing was conducted by
teams of interviewers. Each
interviewing team comprised of
3-4 female interviewers, a field
editor and a supervisor, and a
driver. Each team used a 4 wheel
drive vehicle to travel from
cluster to cluster (and where
necessary within cluster).</em></p>
<p><em>The role of the supervisor was
to coordinator field data
collection activities, including
management of the field teams,
supplies and equipment, finances,
maps and listings, coordinate
with local authorities concerning
the survey plan and make
arrangements for accommodation
and travel. Additionally, the
field supervisor assigned the
work to the interviewers, spot
checked work, maintained field
control documents, and sent
completed questionnaires and
progress reports to the central
office.</em></p>
<p><em>The field editor was responsible
for reviewing each questionnaire
at the end of the day, checking
for missed questions, skip
errors, fields incorrectly
completed, and checking for
inconsistencies in the data. The
field editor also observed
interviews and conducted review
sessions with interviewers.</em></p>
<p><em>Responsibilities of the
supervisors and field editors are
described in the Instructions for
Supervisors and Field Editors,
together with the different field
controls that were in place to
control the quality of the
fieldwork.</em></p>
<p><em>Field visits were also made by a
team of central staff on a
periodic basis during fieldwork.
The senior staff of GenCenStat
also made 3 visits to field teams
to provide support and to review
progress.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p><strong>Data Processing</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Data entry and editing</p></td>
<td><p>The data editing should contain
information on how the data was
treated or controlled for in
terms of consistency and
coherence. This item does not
concern the data entry phase but
only the editing of data whether
manual or automatic.</p>
<ul class="simple">
<li><p>Was a hot deck or a cold deck
technique used to edit the
data?</p></li>
<li><p>Were corrections made
automatically (by program), or
by visual control of the
questionnaire?</p></li>
<li><p>What software was used?</p></li>
</ul>
<p>If materials are available
(specifications for data editing,
report on data editing, programs
used for data editing), they
should be listed here and
provided as external resources.</p>
<dl>
<dt>Example:</dt><dd><p><em>Data editing took place at a
number of stages throughout the
processing, including:</em></p>
<p><em>a) Office editing and coding</em></p>
<p><em>b) During data entry</em></p>
<p><em>c) Structure checking and
completenes</em></p>
<p><em>d) Secondary editing</em></p>
<p><em>e) Structural checking of SPSS
data files</em></p>
<p><em>Detailed documentation of the
editing of data can be found in
the “Data processing guidelines”
document provided as an external
resource.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Software</p></td>
<td><p>List of software used for the key
activities (especially data entry,
editing, tabulation, analysis).</p>
<p>Attributes: Purpose and Software</p>
</td>
</tr>
<tr class="row-even"><td><p>Other processing</p></td>
<td><p>Use this field to provide as much
information as possible on the
data entry design. This includes
such details as:</p>
<ul class="simple">
<li><p>Mode of data entry (manual or
by scanning, in the field/in
regions/at headquarters)</p></li>
<li><p>Computer architecture (laptop
computers in the field,
desktop computers, scanners,
PDA, other; indicate the
number of computers used)</p></li>
<li><p>Software used</p></li>
<li><p>Use (and rate) of double data
entry</p></li>
<li><p>Average productivity of data
entry operators; number of
data entry operators involved
and their work schedule</p></li>
</ul>
<p>Information on tabulation and
analysis can also be provided
here.</p>
<p>All available materials (data
entry/tabulation/analysis
programs; reports on data entry)
should be listed here and
provided as external resources.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>Data were processed in clusters,
with each cluster being processed
as a complete unit through each
stage of data processing. Each
cluster goes through the
following steps:</em></p>
</dd>
</dl>
<ol class="arabic simple">
<li><p><em>Questionnaire reception</em></p></li>
<li><p><em>Office editing and coding</em></p></li>
<li><p><em>Data entry</em></p></li>
<li><p><em>Structure and completeness
checking</em></p></li>
<li><p><em>Verification entry</em></p></li>
<li><p><em>Comparison of verification
data</em></p></li>
<li><p><em>Back up of raw data</em></p></li>
<li><p><em>Secondary editing</em></p></li>
<li><p><em>Edited data back up</em></p></li>
</ol>
<p><em>After all clusters are
processed, all data is
concatenated together and then
the following steps are completed
for all data files:</em></p>
<ol class="arabic simple" start="10">
<li><p><em>Export to SPSS in 4 files
(hh - household, hl -
household members, wm - women,
ch - children under 5)</em></p></li>
<li><p><em>Recoding of variables needed
for analysis</em></p></li>
<li><p><em>Adding of sample weights</em></p></li>
<li><p><em>Calculation of wealth
quintiles and merging into
data</em></p></li>
<li><p><em>Structural checking of SPSS
files</em></p></li>
<li><p><em>Data quality tabulations</em></p></li>
<li><p><em>Production of analysis
tabulations</em></p></li>
</ol>
<p><em>Details of each of these steps
can be found in the data
processing documentation, data
editing guidelines, data
processing programs in CSPro and
SPSS, and tabulation guidelines.</em></p>
<p><em>Data entry was conducted by 12
data entry operators in tow
shifts, supervised by 2 data
entry supervisors, using a total
of 7 computers (6 data entry
computers plus one supervisors’
computer). All data entry was
conducted at the GenCenStat head
office using manual data entry.
For data entry, CSPro version
2.6.007 was used with a highly
structured data entry program,
using system controlled approach
that controlled entry of each
variable. All range checks and
skips were controlled by the
program and operators could not
override these. A limited set of
consistency checks were also
included in the data entry
program. In addition, the
calculation of anthropometric
Z-scores was also included in the
data entry programs for use
during analysis. Open-ended
responses (“Other” answers) were
not entered or coded, except in
rare circumstances where the
response matched an existing code
in the questionnaire.</em></p>
<p><em>Structure and completeness
checking ensured that all
questionnaires for the cluster
had been entered, were
structurally sound, and that
women’s and children’s
questionnaires existed for each
eligible woman and child.</em></p>
<p><em>100% verification of all
variables was performed using
independent verification, i.e.
double entry of data, with
separate comparison of data
followed by modification of one
or both datasets to correct
keying errors by original
operators who first keyed the
files.</em></p>
<p><em>After completion of all
processing in CSPro, all
individual cluster files were
backed up before concatenating
data together using the CSPro
file concatenate utility.</em></p>
<p><em>For tabulation and analysis SPSS
versions 10.0 and 14.0 were used.
Version 10.0 was originally used
for all tabulation programs,
except for child mortality. Later
version 14.0 was used for child
mortality, data quality
tabulations and other analysis
activities.</em></p>
<p><em>After transferring all files to
SPSS, certain variables were
recoded for use as background
characteristics in the tabulation
of the data, including grouping
age, education, geographic areas
as needed for analysis. In the
process of recoding ages and
dates some random imputation of
dates (within calculated
constraints) was performed to
handle missing or “don’t know”
ages or dates. Additionally, a
wealth (asset) index of household
members was calculated using
principal components analysis,
based on household assets, and
both the score and quintiles were
included in the datasets for use
in tabulations.</em></p>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Coding Instructions</strong></p></td>
</tr>
<tr class="row-even"><td><p>Coding Instructions Text</p></td>
<td><p>Describe specific coding
instructions used in data
processing, cleaning, assession,
or tabulation. Use this field to
describe instructions in a human
readable form.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>Due to an error in the data
collection system the value of
“27” was entered for the variable
NBWFBPC which should be coded as
an invalid value of “99”</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>Command</p></td>
<td><p>Provide command code for the coding
instruction. The formalLanguage
attribute identifies the language
of the command code.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>SPSS”&gt;RECODE V1 TO V100
(10 THROUGH HIGH = 0)</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Data Appraisal</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Estimate of sampling error</p></td>
<td><p>For sampling surveys, it is good
practice to calculate and publish
sampling error. This field is
used to provide information on
these calculations. This
includes:</p>
<ul class="simple">
<li><p>A list of ratios/indicators
for which sampling errors were
computed.</p></li>
<li><p>Details regarding the software
used for computing the
sampling error, and reference
to the programs used (to be
provided as external
resources) as the program used
to perform the calculations.</p></li>
<li><p>Reference to the reports or
other document where the
results can be found (to be
provided as external
resources).</p></li>
</ul>
<dl>
<dt>Example:</dt><dd><p><em>Estimates from a sample survey
are affected by two types of
errors: 1) non-sampling errors
and 2) sampling errors.
Non-sampling errors are the
results of mistakes made in the
implementation of data collection
and data processing. Numerous
efforts were made during
implementation of the 2005-2006
MICS to minimize this type of
error, however, non-sampling
errors are impossible to avoid
and difficult to evaluate
statistically.</em></p>
<p><em>If the sample of respondents had
been a simple random sample, it
would have been possible to use
straightforward formulae for
calculating sampling errors.
However, the 2005-2006 MICS
sample is the result of a
multi-stage stratified design,
and consequently needs to use
more complex formulae. The SPSS
complex samples module has been
used to calculate sampling errors
for the 2005-2006 MICS. This
module uses the Taylor
linearization method of variance
estimation for survey estimates
that are means or proportions.
This method is documented in the
SPSS file CSDescriptives.pdf
found under the Help, Algorithms
options in SPSS.</em></p>
<p><em>Sampling errors have been
calculated for a select set of
statistics (all of which are
proportions due to the
limitations of the Taylor
linearization method) for the
national sample, urban and rural
areas, and for each of the five
regions. For each statistic, the
estimate, its standard error, the
coefficient of variation (or
relative error – the ratio
between the standard error and
the estimate), the design effect,
and the square root design effect
(DEFT – the ratio between the
standard error using the given
sample design and the standard
error that would result if a
simple random sample had been
used), as well as the 95 percent
confidence intervals (+/-2
standard errors).</em></p>
<p><em>Details of the sampling errors
are presented in the sampling
errors appendix to the report and
in the sampling errors table
presented in the external
resources.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Other forms data appraisal</p></td>
<td><p>This section can be used to
report any other action taken to
assess the reliability of the
data, or any observations
regarding data quality. This item
can include:</p>
<ul class="simple">
<li><p>For a population census,
information on the post
enumeration survey (a report
should be provided in external
resources and mentioned here).</p></li>
<li><p>For any survey/census, a
comparison with data from
another source.</p></li>
<li><p>Etc.</p></li>
</ul>
<dl class="simple">
<dt>Example:</dt><dd><p><em>A series of data quality tables
and graphs are available to
review the quality of the data
and include the following:</em></p>
</dd>
</dl>
<ul class="simple">
<li><p><em>Age distribution of the
household population</em></p></li>
<li><p><em>Age distribution of eligible
women and interviewed women</em></p></li>
<li><p><em>Age distribution of eligible
children and children for whom
the mother or caretaker was
interviewed</em></p></li>
<li><p><em>Age distribution of children
under age 5 by 3 month groups</em></p></li>
<li><p><em>Age and period ratios at
boundaries of eligibility</em></p></li>
<li><p><em>Percent of observations with
missing information on
selected variables</em></p></li>
<li><p><em>Presence of mother in the
household and person
interviewed for the under 5
questionnaire</em></p></li>
<li><p><em>School attendance by single
year age</em></p></li>
<li><p><em>Sex ratio at birth among
children ever born, surviving
and dead by age of respondent</em></p></li>
<li><p><em>Distribution of women by time
since last birth</em></p></li>
<li><p><em>Scatter plot of weight by
height, weight by age and
height by age</em></p></li>
<li><p><em>Graph of male and female
population by single years of
age</em></p></li>
<li><p><em>Population pyramid</em></p></li>
</ul>
<p><em>The results of each of these
data quality tables are shown in
the appendix of the final report
and are also given in the
external resources section.</em></p>
<p><em>The general rule for
presentation of missing data in
the final report tabulations is
that a column is presented for
missing data if the percentage of
cases with missing data is 1% or
more. Cases with missing data on
the background characteristics
(e.g. education) are included in
the tables, but the missing data
rows are suppressed and noted at
the bottom of the tables in the
report (not in the SPSS output,
however).</em></p>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Data Access</strong></p></td>
</tr>
<tr class="row-even"><td><p>Access authority</p></td>
<td><p>This section is composed of
various sections:
Name-Affiliation-email-URI. This
information provides the contact
person or entity to gain
authority to access the data. It
is advisable to use a generic
email contact such as
<a class="reference external" href="mailto:data&#37;&#52;&#48;popstatsoffice&#46;org">data<span>&#64;</span>popstatsoffice<span>&#46;</span>org</a> whenever
possible to avoid tying access to
a particular individual whose
functions may change over time.</p></td>
</tr>
<tr class="row-odd"><td><p>Confidentiality Declaration</p></td>
<td><p>If the dataset is not anonymized,
we may indicate here what
Affidavit of Confidentiality must
be signed before the data can be
accessed. Another option is to
include this information in the
next element (Access conditions).
If there is no confidentiality
issue, this field can be left
blank.</p>
<p>An example of statement could be
the following:</p>
<p><em>Confidentiality of respondents
is guaranteed by Articles N to NN
of the National Statistics Act of
[date].</em></p>
<p><em>Before being granted access to
the dataset, all users have to
formally agree:</em></p>
<ol class="arabic simple">
<li><p><em>To make no copies of any
files or portions of files to
which s/he is granted access
except those authorized by the
data depositor.</em></p></li>
<li><p><em>Not to use any technique in
an attempt to learn the
identity of any person,
establishment, or sampling
unit not identified on public
use data files.</em></p></li>
<li><p><em>To hold in strictest
confidence the identification
of any establishment or
individual that may be
inadvertently revealed in any
documents or discussion, or
analysis. Such inadvertent
identification revealed in
her/his analysis will be
immediately brought to the
attention of the data
depositor.</em></p></li>
</ol>
<p><em>This statement does not replace
a more comprehensive data
agreement(see Access condition).</em></p>
</td>
</tr>
<tr class="row-even"><td><p>Access conditions</p></td>
<td><p>Each dataset should have an
“Access policy” attached to it.
The IHSN recommends three levels
of accessibility:</p>
<ul class="simple">
<li><p>Public use files, accessible
to all</p></li>
<li><p>Licensed datasets, accessible
under conditions</p></li>
<li><p>Datasets only accessible in a
data enclave, for the most
sensitive and confidential
data.</p></li>
</ul>
<p>The IHSN has formulated standard,
generic policies and access forms
for each one of these three
levels (which each country can
customize to its specific needs).
One of the three policies may be
copy/pasted in this field once it
has been edited as needed and
approved by the appropriate
authority. Before you fill this
field, a decision has to be made
by the management of the data
depositor agency. Avoid writing a
specific statement for each
dataset.</p>
<p>If the access policy is subject
to regular changes, you should
enter here a URL where the user
will find detailed information on
access policy which applies to
this specific dataset. If the
datasets are sold, pricing
information should also be
provided on a website instead of
being entered here.</p>
<p>If the access policy is not
subject to regular changes, you
may enter more detailed
information here. For a public
use file for example, you could
enter information like:</p>
<p><em>The dataset has been anonymized
and is available as a Public Use
Dataset. It is accessible to all
for statistical and research
purposes only, under the
following terms and conditions:</em></p>
<ol class="arabic simple">
<li><p><em>The data and other materials
will not be redistributed or
sold to other individuals,
institutions, or organizations
without the written agreement
of the [National Data
Archive].</em></p></li>
<li><p><em>The data will be used for
statistical and scientific
research purposes only. They
will be used solely for
reporting of aggregated
information, and not for
investigation of specific
individuals or organizations.</em></p></li>
<li><p><em>No attempt will be made to
re-identify respondents, and
no use will be made of the
identity of any person or
establishment discovered
inadvertently. Any such
discovery would immediately be
reported to the [National Data
Archive].</em></p></li>
<li><p><em>No attempt will be made to
produce links among datasets
provided by the [National Data
Archive], or among data from
the [National Data Archive]
and other datasets that could
identify individuals or
organizations.</em></p></li>
<li><p><em>Any books, articles,
conference papers, theses,
dissertations, reports, or
other publications that employ
data obtained from the
[National Data Archive] will
cite the source of data in
accordance with the Citation
Requirement provided with each
dataset.</em></p></li>
<li><p><em>An electronic copy of all
reports and publications based
on the requested data will be
sent to the [National Data
Archive].</em></p></li>
<li><p><em>The original collector of the
data, the [National Data
Archive], and the relevant
funding agencies bear no
responsibility for use of the
data or for interpretations or
inferences based upon such
uses.</em></p></li>
</ol>
</td>
</tr>
<tr class="row-odd"><td><p>Citation requirement</p></td>
<td><p>Citation requirement is the way
that the dataset should be
referenced when cited in any
publication. Every dataset should
have a citation requirement. This
will guarantee that the data
producer gets proper credit, and
that analytical results can be
linked to the proper version of
the dataset. The Access Policy
should explicitly mention the
obligation to comply with the
citation requirement (in the
example above, see item 5). The
citation should include at least
the primary investigator, the
name and abbreviation of the
dataset, the reference year, and
the version number. Include also
a website where the data or
information on the data is made
available by the official data
depositor.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>“National Statistics Office of
Popstan, Multiple Indicators
Cluster Survey 2000 (MICS 2000),
Version 01 of the public use
dataset (April 2001), provided by
the National Data Archive.
www.nda_popstan.org”</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Location of Data Collection</p></td>
<td><p>Location where the data collection
is currently stored. Use the URI
attribute to provide a URN or URL
for the storage site or the actual
address from which the data may be
downloaded.</p></td>
</tr>
<tr class="row-odd"><td><p>URL for Location of Data Collection</p></td>
<td><p>Location where the data collection
is currently stored. Provide a URN
or URL for the storage site or the
actual address from which the data
may be downloaded.</p></td>
</tr>
<tr class="row-even"><td><p>Archive Where Study Originally
Stored</p></td>
<td><p>Statement of collection
availability. An archive may need
to indicate that a collection is
unavailable because it is embargoed
for a period of time, because it
has been superseded, because a new
edition is imminent, etc. It is
anticipated that a controlled
vocabulary will be developed for
this element.</p></td>
</tr>
<tr class="row-odd"><td><p>Availability Status</p></td>
<td><p>Statement of collection
availability. An archive may need
to indicate that a collection is
unavailable because it is embargoed
for a period of time, because it
has been superseded, because a new
edition is imminent, etc. It is
anticipated that a controlled
vocabulary will be developed for
this element.</p></td>
</tr>
<tr class="row-even"><td><p>Deposit Requirement</p></td>
<td><p>Information regarding user
responsibility for informing
archives of their use of data
through providing citations to the
published work or providing copies
of the manuscripts.</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>Disclaimer and Copyright</strong></p></td>
</tr>
<tr class="row-even"><td><p>Disclaimer</p></td>
<td><p>A disclaimer limits the liability
that the Statistics Office has
regarding the use of the data. A
standard legal statement should
be used for all datasets from a
same agency. The IHSN recommends
the following formulation:</p>
<p><em>The user of the data
acknowledges that the original
collector of the data, the
authorized distributor of the
data, and the relevant funding
agency bear no responsibility for
use of the data or for
interpretations or inferences
based upon such uses.</em></p>
</td>
</tr>
<tr class="row-odd"><td><p>Copyright</p></td>
<td><p>Include here a copyright
statement on the dataset, such
as:</p>
<p><em>© 2017, Popstan Central
Statistics Agency</em></p>
</td>
</tr>
<tr class="row-even"><td colspan="2"><p><strong>Contacts</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Contact persons</p></td>
<td><p>Users of the data may need
further clarification and
information. This section may
include the
name-affiliation-email-URI of one
or multiple contact persons.
Avoid putting the name of
individuals. The information
provided here should be valid for
the long term. It is therefore
preferable to identify contact
persons by a title. The same
applies for the email field.
Ideally, a “generic” email
address should be provided. It is
easy to configure a mail server
in such a way that all messages
sent to the generic email address
would be automatically forwarded
to some staff members.</p>
<dl>
<dt>Example:</dt><dd><p><em>Name: Head, Data Processing
Division</em></p>
<p><em>Affiliation: National
Statistics Office</em></p>
<p><em>Email: dataproc&#64;cso.org</em></p>
<p><em>URI: www.cso.org/databank</em></p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="good-practices-for-completing-the-file-description">
<h2>5.3. Good practices for completing the File Description<a class="headerlink" href="#good-practices-for-completing-the-file-description" title="Permalink to this headline">¶</a></h2>
<p>The File Description is the DDI section that aims to provide a detailed
description of each data file. The IHSN has selected six of the
available DDI elements.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>File Citation</p></td>
<td><p>Provides for a full bibliographic
citation option for each data file
described in File Description.</p></td>
</tr>
<tr class="row-even"><td><p>Contents of Files</p></td>
<td><p>A data filename usually provides
little information on its
content. Provide here a
description of this content. This
description should clearly
distinguish collected variables
and derived variables. It is also
useful to indicate the
availability in the data file of
some particular variables such as
the weighting coefficients. If
the file contains derived
variables, it is good practice to
refer to the computer program
that generated it.</p>
<dl class="simple">
<dt>Examples:</dt><dd><ul class="simple">
<li><p><em>The file contains data
related to section 3A of the
household survey questionnaire
(Education of household
members aged 6 to 24 years).
It also contains the weighting
coefficient, and various
recoded variables on levels of
education.</em></p></li>
<li><p><em>The file contains derived
data on household consumption,
annualized and aggregated by
category of products and
services. The file also
contains a regional price
deflator variable and the
household weighting
coefficient. The file was
generated using a Stata
program named
“cons_aggregate.do” available
in the external resources.</em></p></li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr class="row-odd"><td><p>File Producer</p></td>
<td><p>Put the name of the agency that
produced the data file. Most data
files will have been produced by
the survey primary investigator.
In some cases however, auxiliary
or derived files from other
producers may be released with a
data set. This may for example
include CPI data generated by a
different agency, or files
containing derived variables
generated by a researcher.</p></td>
</tr>
<tr class="row-even"><td><p>Version</p></td>
<td><p>A data file may undergo various
changes and modifications. These
file specific versions can be
tracked in this element. This
field will in most cases be left
empty. It is more important to
fill the field identifying the
version of the dataset (see
above).</p></td>
</tr>
<tr class="row-odd"><td><p>Processing Checks</p></td>
<td><p>Use this element if needed to
provide information about the
types of checks and operations
that have been performed on the
data file to make sure that the
data are as correct as possible,
e.g. consistency checking,
wildcode checking, etc. Note that
the information included here
should be specific to the data
file. Information about data
processing checks that have been
carried out on the data
collection (study) as a whole
should be provided in the “Data
editing” element at the study
level.</p>
<p>You may also provide here a
reference to an external resource
that contains the specifications
for the data processing checks
(that same information may be
provided also in the “Data
Editing” filed in the Study
Description section).</p>
</td>
</tr>
<tr class="row-even"><td><p>Files Notes</p></td>
<td><p>This field, aiming to provide
information to the user on items
not covered elsewhere, will in
most cases be left empty.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="good-practices-for-completing-the-variables-description">
<h2>5.4. Good practices for completing the Variables Description<a class="headerlink" href="#good-practices-for-completing-the-variables-description" title="Permalink to this headline">¶</a></h2>
<p>The Variable Description is the section of the DDI document that
provides detailed information on each variable.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td colspan="2"><p><strong>VARIABLES</strong></p></td>
</tr>
<tr class="row-even"><td><p>Names</p></td>
<td><p>These are the names given to the
variables. Ideally, the variable
names should be a maximum of 8
characters, and use a logical
naming convention (e.g., section
(S) and question (Q) numbers to
name the question). If the
variable names do not follow
these principles, DO NOT CHANGE
THE VARIABLE NAMES IN THE
EDITOR, but make recommendations
to the data processor for
consideration for future surveys.</p></td>
</tr>
<tr class="row-odd"><td><p>Labels</p></td>
<td><p>All variables should have a label
that</p>
<ul class="simple">
<li><p>Provides the item or question
number in the original data
collection instrument (unless
item number serves as the
variable name)</p></li>
<li><p>Provides a clear indication of
what the variable contains</p></li>
<li><p>Provides an indication of
whether the variable is
constructed from other items</p></li>
</ul>
<p>Recommendations:</p>
<ul class="simple">
<li><p>Do not use ALL CAPS in labels.</p></li>
<li><p>Make sure that different
variables have different
labels (avoid duplicate
labels).</p></li>
<li><p>For expenditure or income:
indicating the currency and
period of reference is crucial
(e.g. “Annual per capita real
expenditure in local currency”</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p>Width, StartCol, Endcol</p></td>
<td><p>When you import your data files
from Stata or SPSS, the
information on StartCol and
EndCol will be empty. It is
crucial to add this information,
in order to allow users to export
the data to ASCII fixed format.
To do so, use the “Variables &gt;
Resequence” function in the
Editor, for each data file.</p></td>
</tr>
<tr class="row-odd"><td><p>Data type</p></td>
<td><p>Four types of variables are
recognized by the Editot:</p>
<ul class="simple">
<li><p><em>Numeric: Numeric variables
are used to store any number,
integer or floating point
(decimals).</em></p></li>
<li><p><em>Fixed string: A fixed string
variable has a predefined
length (default length is 8
but it can range from 1 to 255
characters in length) which
enables the publisher to
handle this data type more
efficiently.</em></p></li>
<li><p><em>Dynamic string: Dynamic
string variables can be used
to store open-ended
questions.</em></p></li>
<li><p><em>Date: date variables stored
in ISO format
(YYYY-MM-DD?—should specify)</em></p></li>
</ul>
<p>The data type is usually properly
identified when the data is
imported. It is important to
avoid the use of string variables
when this is not absolutely
needed. Such issues must be taken
care of before the data is
imported in the Editor. See the
section on “<a class="reference external" href="#gathering-and-preparing-the-data-set">1. Gathering and
preparing the
dataset</a>”
above.</p>
</td>
</tr>
<tr class="row-even"><td><p>Measure</p></td>
<td><p>The Metadata Editor will allow you
to define the measure of a variable
as:</p>
<ul class="simple">
<li><p><em>Nominal</em>: variable with
numeric assignations for
responses; the number assigned
to each response does not have
a meaning by itself.</p></li>
</ul>
<dl class="simple">
<dt>Example:</dt><dd><p>Variable <em>sex</em>: 1 =
Male, 2 = Female (the number
does not have a meaning by
itself; we could as well have
assigned Male = 2 and Female =
1). When variables are
nominal, we can produce
frequency tables by code, but
calculating mean or standard
deviation of the codes would
not make sense.</p>
</dd>
</dl>
<ul class="simple">
<li><p><em>Ordinal</em>: variable with
numeric assignations and in a
logical sequence. The absolute
size of the number, or the
difference between two numbers
has no meaning. But the
sequence of the number
matters.</p></li>
</ul>
<dl class="simple">
<dt>Example:</dt><dd><p>An example of an
ordinal variable would be a
variable indicating the level
of satisfaction of the
respondent, for example on a
scale of 1 (very unsatisfied)
to 5 (very satisfied).</p>
</dd>
</dl>
<ul class="simple">
<li><p><em>Scale</em>: continuous variables
that have inherent and not
categorical value. Examples of
such variables include the age
of the person, the amount of
income or expenditure, etc.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>CATEGORIES</strong></p></td>
</tr>
<tr class="row-even"><td><p>Categories</p></td>
<td><p>Variable categories are the lists
of codes (and their meaning) that
apply to the variable. The
Editor imports categories and
their labels from the source data
files (SPSS, Stata).</p>
<p>If necessary, add/edit the codes.
Use the Documentation &gt; Create
categories from statistics if the
source dataset did not include
value labels (e,g., when imported
from ASCII). Do not include codes
for “Missing”. The codes for
Missing must be specified in the
“Missing data” field. If you fail
to do that, the summary statistics
(mean, standard deviation, etc)
will be calculated including the
missing code, which will be
considered as a valid value.</p>
<img alt="_images/Page42.png" src="_images/Page42.png" />
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>VARIABLE INFORMATION</strong></p></td>
</tr>
<tr class="row-even"><td><p>Time variable</p></td>
<td><p>This is a check-box used to tag
and identify variables used to
define time.</p></td>
</tr>
<tr class="row-odd"><td><p>Min</p>
<p>Max</p>
</td>
<td><p>Allows modifying the minimum
value of a variable. For each
variable where it makes sense,
you should check that the Min and
Max values are correct. Remember:
if a specific value is used for
“Missing”, this should not be
included in the Min-Max range.
For example, if codes 1 and 2 are
used for Male and Female, and 9
for unknown sex, then the Min
will be 1 and the Max will be 2.
The code 9 must be listed in the
“Missing” codes (see below).</p></td>
</tr>
<tr class="row-even"><td><p>Decimals</p></td>
<td><p>Defines the number of decimal
places of a numeric variable
type.</p></td>
</tr>
<tr class="row-odd"><td><p>Implicit decimals</p></td>
<td><p>This check box is selected only
when a fixed ASCII-type file is
imported and the data file
includes a decimal character. As
the decimal character also
requires a space in the variable
length assignation, it is
important to check this box in
order to assure proper alignment
of the data.</p></td>
</tr>
<tr class="row-even"><td><p>Missing data</p></td>
<td><p>Missing values are those values
that are blank in a data file but
should have been responses and
are within the path or universe
of the questionnaire. Missing
values should always be coded.
Missing values should be
differentiated from “not
applicable” and zero (0) values.</p></td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>STATISTICS</strong></p></td>
</tr>
<tr class="row-even"><td><p>Statistics Options</p></td>
<td><p>Various options exist for
displaying and presenting summary
information of the variable to
the user or the person browsing
the output. Summary statistics
are saved in the DDI document and
become part of the metadata. It
is therefore important to select
the appropriate ones.</p>
<ul class="simple">
<li><p>For nominal variables you want
to be sure that the categories
are well defined and that some
of the summary statistics are
not displayed (such as means
and standard deviations.</p></li>
<li><p>For ordinal values, you want
to be sure that the categories
are displayed if they are
required. Not all ordinal
values will require a
category. In some cases you
may want to include some
summary statistics such as
mean and standard deviation.</p></li>
<li><p>For scale values, you do not
want to define categories and
you may want to include some
summary statistics such as
mean and standard deviation.</p></li>
</ul>
<p>Make sure you do not include
“Frequencies” for variables such
as the household identification
number or enumeration area. This
would produce a useless frequency
table, that would considerably
increase the size of your DDI
file (in general, a very large
DDI file–8 to 10Mb or more–
indicates such a problem).</p>
<p>Make sure also that you do not
include meaningless summary
statistics, such as the mean or
standard deviation calculated on
the codes used for variable SEX.</p>
<p>Notes:</p>
<ul class="simple">
<li><p>Summary statistics such as the
mean or standard deviation are
calculated using all valid
values. If special codes are
used to indicate missing
values, make sure they are
declared in the “Missing”
section. If not, they will be
included in the calculations.
For example, if you use code
99999 for indicating missing
values in a variable on
household expenditure, code
99999 must be listed in the
missing section as follows:</p></li>
</ul>
<img alt="_images/Page43.png" src="_images/Page43.png" />
<ul class="simple">
<li><p>If you modify information such
as the categories or missing
values, you must use the
“Documentation &gt; Update
Statistics” command in the
Editor to refresh the summary
statistics.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td colspan="2"><p><strong>DOCUMENTATION</strong></p></td>
</tr>
<tr class="row-even"><td><p>Definition</p></td>
<td><p>This element provides a space to
describe the variable in detail.
Not all variables require
definition. The following
variables should always be
defined when available in a
questionnaire:</p>
<ul class="simple">
<li><p>Household (attach this
definition to the
“household ID” variable</p></li>
<li><p>Head of household (attach this
definition to the variable
“relationship to the head”</p></li>
<li><p>Urban/rural</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p>Universe</p></td>
<td><p>The universe at the variable
level reflects skip patterns
within-records in a
questionnaire. This information
can typically be copy/pasted from
the survey questionnaire. Try to
be as specific as possible. This
information is very useful for
the analyst.</p>
<p>In many cases, a block of
variables will have the same
universe (for example, a block of
variables on education can all
relate to the “Population aged 6
to 24 year). The Toolkit allows
you to select multiple variables
and enter the universe
information to all variables at
once.</p>
</td>
</tr>
<tr class="row-even"><td><p>Source of information</p></td>
<td><p>Enter information regarding who
provided the information
contained within the variable. In
most cases, the source will be
“Head of household” or “Household
member”. But it may also be:</p>
<ul class="simple">
<li><p>GPS measure (for geographic
position)</p></li>
<li><p>Interviewer’s visual
observation (for type of
dwelling)</p></li>
<li><p>Best informant in community</p></li>
<li><p>Etc.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p>Concepts</p></td>
<td><p>Greater description on the nature
of the variable can be placed in
this element. For example, this
element can provide a clearer
definition for certain variables
(i.e. a variable that provides
information on whether a person
is a household member). In the
case of household membership, a
conceptual definition can be
provided.</p>
<dl class="simple">
<dt>Example:</dt><dd><p><em>A household member is defined as
any person who has been resident
in the household for six months
or more in a given year and takes
meals together OR by default the
head of household, infants under
6 months, newly wedded couples
etc.</em></p>
</dd>
</dl>
</td>
</tr>
<tr class="row-even"><td><p>Pre-question text</p>
<p>Literal question</p>
<p>Post-question text</p>
</td>
<td><p>The <em>pre-question texts</em> are the
instructions provided to the
interviewers and <strong>printed in the
questionnaire before the literal
question</strong>. This does not apply to
all variables. Do not confuse
this with instructions provided
in the interviewer’s manual. With
this and the next two fields, one
should be able to understand how
the question was asked during the
interview. See example below.</p>
<p>The <em>literal question</em> is the
full text of the questionnaire as
the enumerator is expected to ask
it when conducting the interview.
This does not apply to all
variables (it does not apply to
derived variables).</p>
<p>The <em>post-question texts</em> are
instructions provided to the
interviewers, <strong>printed in the
questionnaire after the literal
question</strong>. Post-question can be
used to enter information on
skips provided in the
questionnaire. This does not
apply to all variables. Do not
confuse this with instructions
provided in the interviewer’s
manual. With this and the next
two fields, one should be able to
understand how the question was
asked during the interview. See
example above.</p>
<dl class="simple">
<dt>Example:</dt><dd><p>In the example below
(extracted from a UNICEF-MICS
standard questionnaire), we find
a pre-question, a literal
question and a post-question.</p>
</dd>
</dl>
<img alt="_images/image15.png" src="_images/image15.png" />
<ul class="simple">
<li><p>Pre-question: <em>Check age. If
child is 3 years old or more,
ask:</em></p></li>
<li><p>Literal question: <em>Does (name)
attend any organized learning
or early childhood education
programme, such as private or
government facility, including
kindergarten or community
child care?</em></p></li>
<li><p>Post-question: <em>If answer is 2
or 9 &gt; Goto next module</em></p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p>Interviewer Instruction</p></td>
<td><p>Copy/paste the instructions
provided to the interviewers <strong>in
the interviewer’s manual</strong>. In
cases where some instructions
relate to multiple variables,
repeat the information in all
variables. The Editor allows you
to select multiple variables and
enter the information to all
these variables at once.</p></td>
</tr>
<tr class="row-even"><td><p>Imputation</p></td>
<td><p>The field is provided to record
any imputation or replacement
technique used to correct
inconsistent or unreasonable
data. It is recommended that this
field provide a summary of what
was done and include a reference
to a file in the external
resources section.</p></td>
</tr>
<tr class="row-odd"><td><p>Recoding and derivation</p></td>
<td><p>This element applies to data that
were obtained by recoding
collected variables, or by
calculating new variables that
were not directly obtained from
data collection. It is very
important to properly document
such variables. Poorly documented
variables cannot (or should not)
be used by researchers. In cases
where the recoding or derivation
method was very simple, a full
description can be provided here.
For example, if variable AGE_GRP
was obtained by recoding variable
S1Q3, we could simply mention
<em>“Variable obtained by recoding
the age in years provided in
variable S1Q3 into age groups for
years 0-4, 5-9, …, 60-64, 65 and
over. Code 99 indicates unknown
age.”</em></p>
<p>When the derivation method is
more complex, provide here a
reference to a document (and/or
computer program) to be provided
as an External Resource. This
will be the case for example for
a variable “TOT_EXP” containing
the household annual total
expenditure, obtained from a
household budget survey. In such
case, the information provided
here could be:</p>
<p><em>“This variable provides the
annual household expenditure. It
was obtained by aggregating
expenditure data on all goods and
services, available in sections 4
to 6 of the household
questionnaire. It contains
imputed rental values for
owner-occupied dwellings. The
values have been deflated by a
regional price deflator available
in variable REG_DEF”. All values
are in local currency. Outliers
have been fixed. Details on the
calculations are available in
Appendix 2 of the Report on Data
Processing, and in the Stata
program “aggregates.do” available
in external resources.”</em></p>
</td>
</tr>
<tr class="row-even"><td><p>Security</p></td>
<td><p>This field will be left empty in
most cases. It can be used to
identify variables that are
direct identifiers of the
respondents (or highly
identifying indirect
identifiers), and that should not
be released.</p></td>
</tr>
<tr class="row-odd"><td><p>Notes</p></td>
<td><p>This element is provided in order
to record any additional or
auxiliary information related to
the specific variable.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="good-practices-for-completing-the-external-resources-description">
<h2>5.5. Good practices for completing the External Resources description<a class="headerlink" href="#good-practices-for-completing-the-external-resources-description" title="Permalink to this headline">¶</a></h2>
<p>The External Resources are all materials related to the study others
than the data files. They include documents (such as the questionnaires,
interviewer’s manuals, reports, etc), programs (data entry, editing,
tabulation, and analysis), maps, photos, and others. To document
external resources, the Metadata Editor  uses the Dublin Core metadata
standard (which complements the DDI standard).</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Label</p></td>
<td><p>This is the label that will be
used to display a hyper link to
the attached document. It can be
the title, name, or an
abbreviated version of the title.</p></td>
</tr>
<tr class="row-even"><td><p>Resource</p></td>
<td><p>The resource is used to point to
the file that will be attached
and distributed. The folder where
the document is found is a
relative path and should be the
folder that will be pasted into
the document path. Once you
have pointed to the specified
resource make sure you check file
access by clicking the folder
icon to the right of the entry
field.</p></td>
</tr>
<tr class="row-odd"><td><p>Type</p></td>
<td><p>This is crucial information. A
controlled vocabulary is
provided. The selection of the
type is important as it
determines the way it will be
presented or displayed to the
user in the final output. The
following are the choices:</p>
<ul class="simple">
<li><p>Document Administrative: This
includes materials such as the
survey budget; grant agreement
with sponsors; list of staff
and interviewers, etc.</p></li>
<li><p>Document Analytical: Documents
that present analytical output
(academic papers, etc. This
does not include the
descriptive survey report (see
below).</p></li>
<li><p>Document Questionnaire: the
actual questionnaire(s) used
in the field.</p></li>
<li><p>Document Reference: Any
reference documents that are
not directly related to the
specific dataset, but that
provide background information
regarding methodology, etc.
For international standard
surveys, this may for example
include the generic guidelines
provided by the survey
sponsor.</p></li>
<li><p>Document Report: Survey
reports, studies and other
reports that use the data as
the basis for their findings.</p></li>
<li><p>Document Technical:
Methodological documents
related to survey design,
interviewer’s and supervisor’s
manuals, editing
specifications, data entry
operator’s manual, tabulation
and analysis plan, etc.</p></li>
<li><p>Document Other: Miscellaneous
items</p></li>
<li><p>Audio: audio type files.</p></li>
<li><p>Map: Any cartographic
information.</p></li>
<li><p>Photo: Photos can provide good
documentary evidence of a
survey.</p></li>
<li><p>Program: programs generated
during data entry and analysis
(data entry, editing,
tabulation and analysis).
These can be zipped together
(include a brief summary
report to describe the
contents)</p></li>
<li><p>Table: Tabulations such as
confidence intervals that may
not be included in a general
report.</p></li>
<li><p>Video: video type files
provided as additional visual
information</p></li>
<li><p>Website: Link to related
website(s), such as a link to
a Redatam server, or to the
website of the survey sponsor
in the case of international
survey programs like the DHS,
LSMS, or MICS).</p></li>
<li><p>Database: any databases
related to the survey (e.g., a
Devinfo database providing the
aggregated results of the
survey).</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p>Title</p></td>
<td><p>Full title of the document as it
is provided on the cover page.</p></td>
</tr>
<tr class="row-odd"><td><p>Subtitle</p></td>
<td><p>Subtitle if relevant.</p></td>
</tr>
<tr class="row-even"><td><p>Author(s)</p></td>
<td><p>Include all authors that are
listed on the report.</p></td>
</tr>
<tr class="row-odd"><td><p>Date Created</p></td>
<td><p>Date of the publication of the
report or resource (at least
month and year). For reports,
this is most likely stated on the
cover page of the document. For
other types of resources, put
here the date the resource was
produced.</p></td>
</tr>
<tr class="row-even"><td><p>Country</p></td>
<td><p>The country (or countries) that
are covered by the associated
document.</p></td>
</tr>
<tr class="row-odd"><td><p>Language</p></td>
<td><p>Use the Language element to list
all languages which appear in a
resource. The languages should be
selected from the drop-down list,
and each language should appear
on its own line. The proposed
controlled vocabulary is based on
ISO 639-3s.</p></td>
</tr>
<tr class="row-even"><td><p>Format</p></td>
<td><p>The file format provides
information on the kind of
electronic document being
provided. This includes: PDF,
Word, Excel etc. This is a
controlled vocabulary. If the
controlled vocabulary does not
provide the format you need, type
it (or add it in the controlled
vocabulary using the Editor
Template Editor). Providing
information on the format will
inform the user on the software
needed to open the file.</p></td>
</tr>
<tr class="row-odd"><td><p>ID Number</p></td>
<td><p>If there is a unique ID number
which references the document
(such as a Library of Congress
number or a World Bank
Publication number) include this
as the ID Number.</p></td>
</tr>
<tr class="row-even"><td><p>Contributor(s)</p></td>
<td><p>Include the names of all
organizations that have been
involved or contributed to
producing the publication. This
included funding sources as well
as authoring entities.</p></td>
</tr>
<tr class="row-odd"><td><p>Publisher(s)</p></td>
<td><p>Include the official
organization(s) accredited with
disseminating the report.</p></td>
</tr>
<tr class="row-even"><td><p>Rights</p></td>
<td><p>Some resources are protected by
copyrights. Use the Rights
element to provide a clear and
complete description of the usage
rights if relevant.</p></td>
</tr>
<tr class="row-odd"><td><p>Description</p></td>
<td><p>A brief description of the
resource.</p></td>
</tr>
<tr class="row-even"><td><p>Abstract</p></td>
<td><p>An abstract of the content of the
resource.</p></td>
</tr>
<tr class="row-odd"><td><p>Table of Contents</p></td>
<td><p>Use the Table of Contents element
to list all sections of a report,
questionnaire, or other document.
When copying a table of contents
from another file into a project,
pay close attention to the
formatting as tabs, indents, and
fonts may not be preserved.
Because the text cannot be
formatted, adopting strategies
such as placing chapter titles in
capital letters can help keep a
table of contents organized.
Including page numbers is not
crucial.</p></td>
</tr>
<tr class="row-even"><td><p>Subjects</p></td>
<td><p>The key topics discussed in the
resource can be listed in the
Subjects element. Although the
IHSN Resource Template does not
include a controlled vocabulary
for this element, organizations
may opt to modify the template
and establish a set list of
subjects which all of their
projects should use when
documenting studies.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="creating-variable-groups">
<h1>6. Creating variable groups<a class="headerlink" href="#creating-variable-groups" title="Permalink to this headline">¶</a></h1>
<p>Variable groups are optional, but will help organize the data for the
user into specific subject of use categories. This will be particularly
useful to the user in the case of data files that contain many variables
and are not organized by topic (some flat files contain hundreds or even
thousands of variables).</p>
<p>The Metadata Editor allows you to group variables found in various separate
data files. For example, education data may be found in various locations
and the disparate variables grouped together. Also, a same variable can
belong to more than one group.</p>
<p>Variable groups are “virtual”. The variables themselves are not moved or
grouped. They remain untouched in the data files.</p>
<p>The variable groups will appear under a menu item “Data dictionary”.
The only reason for grouping variables is to allow users to easily
locate variables related to their topic of interest. If your dataset
contains very few variables, there is no justification for grouping them.</p>
<p>If you decide to create variable groups (and sub-groups if needed), make
sure that ALL variables in the dataset belong to at least one group.</p>
<p>Variable groups also have their own DDI elements which include Type,
Label, Text, Definition, Universe, and Notes. These elements are
optional and will in most cases be left empty.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>Type</p></td>
<td><p>This is a controlled vocabulary
field. It best identifies the
manner the variables are grouped
together. This field is optional.</p></td>
</tr>
<tr class="row-even"><td><p>Label</p></td>
<td><p>The label used to identify the
group should be clear and relate
to the type chosen. If these are
grouped by subject, then the
subject should be clearly stated
etc.</p></td>
</tr>
<tr class="row-odd"><td><p>Text</p></td>
<td><p>Include additional text to
clarify the reason or purpose for
grouping the variables. This
field is optional.</p></td>
</tr>
<tr class="row-even"><td><p>Definition</p></td>
<td><p>This optional field is used to
define the variable group.</p></td>
</tr>
<tr class="row-odd"><td><p>Universe</p></td>
<td><p>This optional field defines the
universe relevant to the selected
grouped variables. The variables
for example can be grouped as
“Fertility Data” and the universe
restricted to women between the
ages of 15-49.</p></td>
</tr>
<tr class="row-even"><td><p>Notes</p></td>
<td><p>Additional space for further
optional explanatory notes.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="running-validations-and-diagnostics">
<h1>7. Running validations and diagnostics<a class="headerlink" href="#running-validations-and-diagnostics" title="Permalink to this headline">¶</a></h1>
<p>The Metadata Editor includes a useful series of diagnostic and validation
modules (see the drop down menu <em>Tools</em>): these range from very simple
validations (such as the <em>Tools-Validate Metadata</em>) to complex visual
displays that iterate through each variable and provides feedback to the
archivist at the variable level.</p>
<ul class="simple">
<li><p><em>Validate Metadata</em>: verifies that all mandatory fields are filled
in.</p></li>
<li><p><em>Validate External Resources</em>: verifies all mandatory fields in the
External Resources are filled in.</p></li>
<li><p><em>Health Check</em>: displays a popup window that provides some information
and diagnostics regarding the R package. The Metadata Editor uses R
to import and export the data. The health check option tells the which
version of R is being used on the machine. In addition, the Health
Check will provide information on the Environment Path and the result
of the execution of the R script.</p></li>
<li><p><em>Validate Dataset Relations</em>: this option is used to validate
hierarchically related datasets. The ‘Base key variables’ should be
the variables that uniquely identify a case within that file.</p></li>
<li><p><em>Translation Manager</em>: provides the user with the ability to translate
the interface of the Metadata Editor into any language. Selecting this
option will display the Translation Manager interface. When using the
option for the first time, the English template will be displayed with
all the labels that require translation.</p></li>
</ul>
<p>In addition to these validations, it is recommended that you generate
the DDI document (in the Editor, use the Export DDI” function) and
verify the size of the resulting [.xml] file. A fully documented survey
with a large number of variables should not produce a file larger than
10Mb. Very large DDI files often indicate errors in the selection of
summary statistics (for example, frequencies are produced for a variable
like the household ID in a sample household file).</p>
</div>
<div class="section" id="generating-the-survey-documentation-in-pdf">
<h1>8. Generating the survey documentation in PDF<a class="headerlink" href="#generating-the-survey-documentation-in-pdf" title="Permalink to this headline">¶</a></h1>
<p>Once you are confident that all necessary checks have been completed,
you may generate the survey documentation in PDF. The Metadata Editor
includes a useful tool for producing a PDF document summarizing all
metadata entered in the Editor (see Documentation &gt; PDF Documentation).
Generating this report is one of the final stages of properly preparing
a survey for publication and dissemination. If previous versions exist
and changes have been made to the data files or the metadata make sure
you re-run the PDF generator.</p>
<p>This report should be generated, saved and attached as an <em>External
Resource</em>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><dl class="simple">
<dt><strong>!</strong></dt><dd><p>The PDF report will include a list of all external resources
related to the study. This list should include this PDF report
itself. <strong>Before</strong> you generate it, make sure you create one entry
in the External Resources for documenting this report. Immediately
after you generate the PDF report, import it in the Editor.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p>One thing to keep in mind is that in a survey with a large number of
variables may produce a document that is very long. If the report is in
excess of 300 or 350 pages, you may want to split this report (e.g.,
produce one report with the study metadata, and one with the files and
variables metadata), or change the content options (e.g., not including
a frequency table for all variables).</p>
<p>If your agency has a website, you may upload this PDF directly to the
web server. The IHSN recommends the use of a proper DDI-compliant
cataloguing system, such as the one provided by its National Data
Archive (NADA) application. NADA is an open source package, available
free of charge at www.surveynetwork.org.</p>
</div>
<div class="section" id="independent-quality-review">
<h1>9. Independent quality review<a class="headerlink" href="#independent-quality-review" title="Permalink to this headline">¶</a></h1>
<p>An independent review of the data and metadata is highly recommended
prior to publishing the final output. The Appendix provides a blank
review form (the <em>DDI Reviewer’s Feedback Form</em>) to be used by an
external reviewer.</p>
<p>The external review can be based on:</p>
<ol class="arabic simple">
<li><p>The DDI file (xml file, containing no microdata and no external
resources)</p></li>
<li><p>The Metadata Editor project (containing microdata and DDI/DCMI metadata)</p></li>
<li><p>The PDF Document</p></li>
<li><p>The Microdata</p></li>
</ol>
<p>The preferred option is to review the metadata and microdata, as it allows a
full check of the final output. If data are highly confidential and cannot
be shared with the reviewer, options 1-3 are the most appropriate.</p>
<p>In order to prepare for the independent quality review, proceed to step
10 if you will use options three or four. Follow the guidance there, and
then finalize the archiving before producing the final output. Else,
send the DDI-XML to the reviewer.</p>
</div>
<div class="section" id="section-a-data-validations-in-stata-practical-examples">
<h1>Section A . Data Validations in Stata: Practical Examples<a class="headerlink" href="#section-a-data-validations-in-stata-practical-examples" title="Permalink to this headline">¶</a></h1>
<p><strong>Example 1 . Check for unique identifiers (single variable)</strong></p>
<p>This example uses a Country Opinion Survey and uses the Stata command
<em>-isid-</em> to check whether the variable “id” uniquely identifies the
observations. Each row of the data represents a different Country’s
Stakeholders and the variable that identifies each one is named “id”.</p>
<img alt="_images/Pag50_1.png" src="_images/Pag50_1.png" />
<p>If, after running the <em>-isid-</em> command you have not got an error
message, it indicates that the “id” is unique and identifies each
unit of analysis.</p>
<p><strong>Example 2 . Check for unique identifiers (single variable)</strong></p>
<p>For this example, we use the same data than <em>Example 1</em>, but in this
case, there are some hypothetical observations with the same values
for the variable “id”. The highlight observations are the duplicates
IDs.</p>
<img alt="_images/Pag50_2.png" src="_images/Pag50_2.png" />
<p>Since there are not unique IDs in the data, it is also useful to see
the list of all duplicates. To do that, we can use the Stata command
<em>-duplicates list-</em>.</p>
<img alt="_images/Pag51_1.png" src="_images/Pag51_1.png" />
<p><strong>Example 3 . Check for unique identifiers (ID made of multiple variables)</strong></p>
<p>The Multiple Indicator Cluster Survey at Women-level data is used in this
example. According to the study’s metadata, the unique identification of
each woman is the combination of variables HH1 (Cluster Number), HH2
(Household Number) and Ln (Line Number of women), so instead of checking
the unique identifier in just one variable, we are checking this condition
in this group of variables.</p>
<img alt="_images/Pag51_2.png" src="_images/Pag51_2.png" />
<p>After running this validation, it is possible to see that the combination
of “HH1”, “HH2” and “ln” generates a unique ID.</p>
<p><strong>Example 4 . Check for duplicate observations</strong></p>
<p>This example uses the dataset mentioned in example 2, in which there are
3 duplicated identifiers.</p>
<img alt="_images/Pag52_1.png" src="_images/Pag52_1.png" />
<p>As shown, 446 records are unique in the database, but there are six
observations for which there are two copies of each one. Now, it is
necessary to identify duplicates. The code below allows one to generate
a variable that tags the duplicates with a value 1 or more, depending
on the number of times a record is duplicated.</p>
<img alt="_images/Pag52_2.png" src="_images/Pag52_2.png" />
<p>The table above shows that records with the IDs 101, 104 and 111 each
have one duplicate.</p>
<p><strong>Example 5 . Check the merge between datafiles</strong></p>
<p>The code below helps us combine the data collected at the
individual-level with the data collected at the household-level.
In this case, we have two hierarchical datasets, in the household data
each row represents one household, and each household has members or
individuals. So, we need to combine many observations from one data set
(individual-level) with one observation from the other (household-level).
The ID of the household data set is the unique identifier that we are
using for the merge (“HH1”and “HH2”).</p>
<img alt="_images/Pag53_1.png" src="_images/Pag53_1.png" />
<p>The report shows that all observations in the Individual file have a
corresponding household in the household data set and that all households
have at least one member. However, let’s consider a hypothetical example
that contains some records that do not match, below the results of the merge:</p>
<img alt="_images/Pag53_2.png" src="_images/Pag53_2.png" />
<p>The merge command resulted in: 15 nonmatched observations originated from
the master data and 2 from the using data. The inconsistencies between
databases could be the result of a data entry error or processing errors
and these also need to be referred to the data producer before documentation
begins.</p>
<p><strong>Example 6 . Check variables full of missing values</strong></p>
<p>In the example above, there are 3 variables (WM1_1, WM3_1 and WM5_1) full
of missing values. As shown in the table, the <em>-misstable summarize-</em> command
allows one to identify all those cases at once. It is like tabulating every
single variable to identify missing values but more efficiently.</p>
<img alt="_images/Pag54_1.png" src="_images/Pag54_1.png" />
<p><strong>Example 7 . Check the completeness of the data files</strong></p>
<p>This example shows how you can check for discrepancies (if any) between
the variables from the MICS women’s questionnaire and the data set.</p>
<img alt="_images/Pag55_1.png" src="_images/Pag55_1.png" />
<p>As shown, this dataset contains all variables from the section “Woman’s
background,” and they are organized according to the questionnaire.
The comparison between variables in the questionnaire to those in the
data set should be made for every section in the questionnaire.</p>
<p><strong>Example 8 . Check all variables are labelled</strong></p>
<img alt="_images/Pag55_2.png" src="_images/Pag55_2.png" />
<p>The following Form is available at www.surveynetwork.org</p>
<img alt="_images/image16.png" src="_images/image16.png" />
<img alt="_images/image17.png" src="_images/image17.png" />
<img alt="_images/image18.png" src="_images/image18.png" />
<img alt="_images/image19.png" src="_images/image19.png" />
<img alt="_images/image20.png" src="_images/image20.png" />
<img alt="_images/image21.png" src="_images/image21.png" />
<img alt="_images/image22.png" src="_images/image22.png" />
<img alt="_images/image23.png" src="_images/image23.png" />
<img alt="_images/image24.png" src="_images/image24.png" />
<img alt="_images/image25.png" src="_images/image25.png" />
<img alt="_images/image26.png" src="_images/image26.png" />
<img alt="_images/image27.png" src="_images/image27.png" />
<img alt="_images/image28.png" src="_images/image28.png" />
<img alt="_images/image29.png" src="_images/image29.png" />
<img alt="_images/image30.png" src="_images/image30.png" />
<img alt="_images/image31.png" src="_images/image31.png" />
<img alt="_images/image32.png" src="_images/image32.png" />
<img alt="_images/image33.png" src="_images/image33.png" />
<img alt="_images/image34.png" src="_images/image34.png" />
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets">1</span></dt>
<dd><p>DDI (Data Documentation Initiative) and DCMI (Dublin Core Metadata
Initiative) are international XML metadata specifications. For more
information on these standards and on the IHSN Toolkit, please visit
<a class="reference external" href="http://www.surveynetwork.org">www.surveynetwork.org</a>.</p>
</dd>
<dt class="label" id="id3"><span class="brackets">2</span></dt>
<dd><p>See section 3 – <em>Importing data and establishing relationships</em> for
more information on key variables.</p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>In Stata, this can be done through the use of the <em>group</em> function
from the <em>egen</em> command. For example, to create a variable hhid based
on a combination of variables <em>province</em>, <em>district</em>, <em>ea</em> and
<em>hhnum</em>, use the command “egen hhid=group(province district ea hh_num
)”.</p>
</dd>
</dl>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Quick Reference Guide for Data Archivists</a></li>
<li><a class="reference internal" href="#content">Content</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#before-you-start-organizing-your-files">Before you start: organizing your files</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gathering-and-preparing-the-data-set">1. Gathering and preparing the data set</a><ul>
<li><a class="reference internal" href="#data-files-should-be-organized-in-a-hierarchical-format">1.2. Data files should be organized in a hierarchical format</a></li>
<li><a class="reference internal" href="#datasets-with-multiple-units-of-analysis-should-be-stored-in-different-data-files">1.2. Datasets with multiple units of analysis should be stored in different data files</a></li>
<li><a class="reference internal" href="#columns-in-a-dataset-should-represent-variables-not-values">1.3. Columns in a dataset should represent variables, not values</a></li>
<li><a class="reference internal" href="#each-observation-in-every-file-must-have-a-unique-identifier">1.4. Each observation in every file must have a unique identifier</a></li>
<li><a class="reference internal" href="#identifying-duplicate-observations">1.5. Identifying duplicate observations</a></li>
<li><a class="reference internal" href="#ensure-that-each-individual-dataset-can-be-combined-into-a-single-database">1.6. Ensure that each individual dataset can be combined into a single database</a></li>
<li><a class="reference internal" href="#check-for-variables-with-missing-values">1.7. Check for variables with missing values</a></li>
<li><a class="reference internal" href="#check-improper-value-ranges">1.8. Check Improper value ranges</a></li>
<li><a class="reference internal" href="#verify-that-the-number-of-records-in-each-file-corresponds-to-what-is-expected">1.9. Verify that the number of records in each file corresponds to what is expected</a></li>
<li><a class="reference internal" href="#datasets-must-contain-all-variables-from-the-questionnaire-and-be-in-a-logic-sequence">1.10. Datasets must contain all variables from the questionnaire and be in a logic sequence</a></li>
<li><a class="reference internal" href="#include-the-relevant-weighting-coefficients-and-variables-identifying-the-stratification-levels">1.11. Include the relevant weighting coefficients and variables identifying the stratification levels</a></li>
<li><a class="reference internal" href="#variables-and-codes-for-categorical-variables-must-be-labelled">1.12. Variables and codes for categorical variables must be labelled</a></li>
<li><a class="reference internal" href="#temporary-calculated-or-derived-variables-should-not-be-disseminated">1.13.  Temporary, calculated or derived variables should not be disseminated</a></li>
<li><a class="reference internal" href="#check-that-the-data-types-are-correct">1.14. Check that the data types are correct</a></li>
<li><a class="reference internal" href="#datasets-must-not-have-directed-identifiers">1.15. Datasets must not have directed identifiers</a></li>
<li><a class="reference internal" href="#compress-the-variables-to-reduce-the-file-size">1.16. Compress the variables to reduce the file size</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gathering-and-preparing-the-documentation">2. Gathering and preparing the documentation</a></li>
<li><a class="reference internal" href="#importing-data-and-establishing-relationships">3. Importing data and establishing relationships</a></li>
<li><a class="reference internal" href="#importing-external-resources">4. Importing external resources</a></li>
<li><a class="reference internal" href="#completing-metadata">5. Completing metadata</a><ul>
<li><a class="reference internal" href="#good-practices-for-completing-the-document-description">5.1. Good practices for completing the Document Description</a></li>
<li><a class="reference internal" href="#good-practices-for-completing-the-study-description">5.2. Good practices for completing the Study Description</a></li>
<li><a class="reference internal" href="#good-practices-for-completing-the-file-description">5.3. Good practices for completing the File Description</a></li>
<li><a class="reference internal" href="#good-practices-for-completing-the-variables-description">5.4. Good practices for completing the Variables Description</a></li>
<li><a class="reference internal" href="#good-practices-for-completing-the-external-resources-description">5.5. Good practices for completing the External Resources description</a></li>
</ul>
</li>
<li><a class="reference internal" href="#creating-variable-groups">6. Creating variable groups</a></li>
<li><a class="reference internal" href="#running-validations-and-diagnostics">7. Running validations and diagnostics</a></li>
<li><a class="reference internal" href="#generating-the-survey-documentation-in-pdf">8. Generating the survey documentation in PDF</a></li>
<li><a class="reference internal" href="#independent-quality-review">9. Independent quality review</a></li>
<li><a class="reference internal" href="#section-a-data-validations-in-stata-practical-examples">Section A . Data Validations in Stata: Practical Examples</a></li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/index.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="#">Guide for Data Archivists  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Olivier Dupriez, Diana Marcela Sanchez Castro, Matthew Welch.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.
    </div>
  </body>
</html>